\chapter{Surface Electromyography Task}
\label{chap:emg}

The previous Chapter shows the benefits of applying concurrent bandwidth feedback to continuous motor control, but did not explore if this feedback can be successfully applied to more discrete tasks.
To further investigate the utility of concurrent bandwidth feedback, we applied it to an electromyography-based control task.
This experiment also investigated the difference between using concurrent and terminal feedback as potential training strategies to reduce the required time to use electromyography control.
Portions of this chapter were originally published in the conference proceedings for AIAA SciTech 2020 \citep{doi:10.2514/6.2020-1110}.

% \title{The Effects of Training Methodology on Performance, Workload, and Trust During Human Learning of a Computer-Based Task}

% \author{Sarah M. O'Meara\footnote{Graduate Student Researcher, Mechanical and Aerospace Engineering Department.} and John A. Karasinski\footnote{Graduate Student Researcher, Mechanical and Aerospace Engineering Department, Student Member AIAA.} and Casey L. Miller\footnote{Research Assistant, Mechanical and Aerospace Engineering Department.} and Sanjay S. Joshi\footnote{Director, Robotics, Autonomous Systems, and Controls Laboratory, Professor, Mechanical and Aerospace Engineering Department.} and Stephen K. Robinson\footnote{Principal Investigator, Human/Robotics/Vehicle Integration and Performance Lab, Professor, Mechanical and Aerospace Engineering Department, Associate Fellow AIAA.}}
% \affil{University of California, Davis, Davis, CA, 95616, USA}

\section{Introduction}
% Biophysical monitoring during aviation operations has recently gained increased interest as a safety feature and a means to create an adaptive cockpit.
% Safety-related concerns include cognitive workload~\citep{RN1, RN2}, muscle strain~\citep{RN3, RN4, RN5}, and security~\citep{RN6}.
% Pilots may develop inattentional deafness to auditory alarms, but biophysical monitoring has the potential to predict these occurrences~\citep{RN7}, discriminate between cognitive loads~\citep{RN1}, and predict cognitive fatigue which results in missed auditory targets~\citep{RN2}.
% The potential causes of muscle fatigue and strain has also been studied in helicopter pilots~\citep{RN3, RN4, RN5}, as well as electromyography (EMG) measurement accuracy~\citep{RN8}.
% EMG has been used in aviation research to predict and warn pilots of G-Induced Loss of Consciousness~\citep{RN9, RN10}, to discriminate between novice and experienced pilots~\citep{RN11}, to control forces during emergency maneuvers~\citep{RN12}, and to command pitch and bank rates of an aircraft simulation~\citep{RN13}.

% More recently, incorporating biophysical measurements has been suggested for UAV operation~\citep{RN14}.
% EMG control has also been applied to robotics~\citep{RN15, RN16, RN17, RN18} with potential aerospace applications, such as tele-operations~\citep{RN19}.
% In addition to tele-operations control~\citep{RN20, RN21}, EMG inputs have been used to modulate robotic arm stiffness for more precise tasks~\citep{RN22, RN23}.
% While these studies have developed control strategies, they have not addressed the training aspect which is essential for the critical and complex environments found in aerospace operations.
% Development of more sophisticated and integrated human-automation interfaces is clearly a trend in aviation, and more broadly in aerospace as a whole.

% \subsection{Selected Training Methodologies}
Training novice users to effectively use electromyography (EMG) control can be a long and difficult task~\citep{RN24}.
EMG control has been applied to robotics~\citep{RN15, RN16, RN17, RN18} and tele-operations~\citep{RN19}, and has been suggested for UAV operation~\citep{RN14}, but long learning times have generally prevented EMG from being used operationally.
The use of augmented feedback strategies, however, have been shown to help reduce training times.
Augmented feedback provides information that ``cannot be elaborated without an external source; thus, it is provided by a trainer or a display'' and has been shown to effectively improve performance in a wide variety of motor tasks~\citep{sigrist_augmented_2013}.
Biofeedback, which applies augmented feedback strategies to physiological signals such as EMG, has proven to be a useful tool for improving performance and assisting in rehabilitation~\citep{RN26}.
Researchers have investigated various augmented biofeedback techniques and have found them to help subjects to ``become more cognizant of their own EMG signal'', allowing for better control~\citep{RN27}.
A recent review of the biofeedback literature suggests that ``[b]iofeedback is more effective than usual therapy,'' though they also note that ``[f]urther research is required to determine the long-term effect [biofeedback has] on learning''~\citep{RN28}.

Augmented feedback can be split into two large categories describing when the feedback is presented to a subject.
Concurrent feedback is presented in real-time, as subjects complete a task, while terminal feedback is presented after the task is complete.
In general, concurrent feedback has been shown to be more useful with increasing functional task complexity, while terminal feedback is often less useful when complexity is high~\citep{sigrist_augmented_2013}.
Concurrent feedback has recently shown great promise in EMG control, though less progress has been made comparing the effects of terminal feedback strategies or investigating long-term learning effects~\citep{RN29, RN30, RN31, RN32}.

Additionally, research into the bayesian theory of motor adaptation, which suggests that increased errors and decreased visual uncertainty lead to faster adaptation, may be a useful training methodology for reducing training times.
Research into motor adaptation and surface EMG (sEMG) control has showed great promise compared to traditional techniques~\citep{RN33}.
Recent research at UC Davis has further investigated the use of motor adaptation for two-dimensional myoelectric control~\citep{RN35}.
\citeauthor{RN35} found that subjects were more successful at hitting targets when exposed to control perturbations compared to a control group, and concluded by suggesting that ``exposure to a variable mapping encourages exploratory behavior and underlies a change in adaption rate, which could potentially be used to train myoelectric control users.''
Motor adaptation has not previously been used as a training methodology, however, and it is unclear how it would compare to an augmented feedback based methodology.

\subsection{Trust in Automation}
Trust is an important factor when considering human-automation interaction, and inappropriate trust can lead to the disuse or misuse of automated systems.
Trust is ``the attitude that an agent will help achieve an individual's goals in a situation characterized by uncertainty and vulnerability''~\citep{lee_trust_2004}.
The reliability of a system, in particular, has been shown to be an important aspect of an operator's trust in a system~\citep{RN38}.
While there have been many proposed models for trust, \citeauthor{RN39}'s three layer model deserves particular attention.
After performing a systematic review of the literature, they developed a three-layer model of trust which is split between dispositional trust, situational trust, and learned trust.
Though researchers have little control over dispositional trust, they can affect situational trust by varying an experimental interface or environment and learned trust can be evaluated using repeated measures.

\subsection{Summary}
% Our recent work at University of California (U.C.), Davis includes three studies which have shown that concurrent feedback techniques can improve performance and have the potential to reduce cognitive workload in especially demanding tasks.
% We investigated the effects of concurrent feedback in a simulated, four degree of freedom manually-controlled spacecraft inspection task~\citep{karasinski_real-time_2017}.
% Subjects in a feedback group performed the task much faster and more accurately than those in a control group and reported a significantly lower workload.
% We also investigated the effects of concurrent feedback on performance in a three-axis manual tracking task~\citep{karasinski_evaluating_2019}.
% We found that subjects could use concurrent visual feedback to better learn the depth cues provided by an augmented reality headset.
% Subjects were able to retain their performance improvement when the feedback was removed.
% Finally, we investigated the effects of using concurrent feedback to train an aircraft flight task with variable modes of difficulty~\citep{RN42}.
% Subjects exposed to the feedback immediately performed significantly better in every aspect of the task, continued this trend through the study, and retained these performance benefits after the feedback was removed in retention trials.

In this study, we address the effects of training methodology on performance, workload, and trust during a computer-based Fitts's Law cursor-to-target task~\citep{RN43}.
The training methodologies evaluated were concurrent and terminal augmented feedback and motor adaptation based on variable mapping of control inputs.
To test if the benefits provided by these training methodologies were acting to improve learning or simply being used as performance enhancers when present, we removed the feedback and variable mapping at the end of the study.

\section{Materials and Methods}
\subsection{Subjects and Experimental Setup}

55 subjects were recruited from the University of California, Davis's Psychology department.
Subjects were excluded if they had a history of neuromuscular disorders, physical limitations of dominant arm, or prior sEMG control experience.
Of the 55 subjects recruited, 48 completed the complete protocol and had an average age of 20.07 years (SD = 1.39).
This study was approved by the University of California, Davis Institutional Review Board (Project \#1461183-1), and subjects provided written consent and were compensated in the form of university research credits.

The experimental setup for attaching the electrodes for the EMG control followed \citeauthor{RN44}, and two electrodes (ConMed 1620 Ag/AgCl center snap) approximately 2.5 cm apart were placed on the dominant hand side near the extensor digitorum proximal attachment.
The signal from the electrodes was acquired as described in \citet{RN44}, and the signal processing followed \citet{RN45}.
The raw signal was windowed, and the root-mean-square (RMS) value for each window was calculated, normalized by a manually set calibration constant, and incorporated into a moving average window to yield $\bar{x}$, see Equation~\ref{eq:emgvelocity}.

\subsection{Experimental Design and Subject Groups}

Subjects in the experiment used EMG to control the cursor in a 2D center-out Fitts's Law task.
The task took place in a normalized area of -1 to 1 units in each direction.
To control the cursor, subjects input a series of three pulsive EMG commands which indicated a direction and velocity of the cursor.
For the pulse to be registered by the system, it needed to cross threshold value, $l_1$, which was nominally set to 0.20.
The first two pulses were each classified as ``short'' or ``long'', where long was indicated by holding the pulse for greater than 0.5 seconds, and different combinations of these pulses formed a 2-bit code.
The different codes represented up, down, left, and right, and two ``short'' pulses, for example, selected the up command.
After the first two pulses were entered and recognized as a movement code, the third pulse could be used to command the velocity of the cursor.
The cursor velocity was defined by Equation~\ref{eq:emgvelocity},
\begin{equation}
	\label{eq:emgvelocity}
	v= v_c+\left(v_m-v_c\right)\left[\frac{\left(\bar{x}-l_2\right)}{\left(1-l_2\right)}\right]
\end{equation}
where $v_c$ was the minimum velocity (0.05 units/second), $v_m$ was the maximum velocity (0.50 units/second), $l_2$ was 0.30, and $\bar{x}$ was the filtered, averaged sEMG input.
The interface and this control strategy was first presented in \citet{RN45}, and further pilot studies were conducted to determine a maximum time of 60 seconds for subjects to complete a Trial.

Subjects were randomly assigned to one of four groups (12 subjects per group), and each was exposed to separate training methodology:
\begin{enumerate}
	\item The Control group trained solely through repetition.
	\item The Concurrent Feedback group received visual feedback during the task which indicated when the sEMG signal exceeded the threshold value, $l_1$, for selecting commands.
	\item The Terminal Feedback group received visual feedback during the task after they successfully entered a command.
	\item The Adaptive Threshold group was the same as the Control group, but the threshold value, $l_1$, varied Trial-to-Trial and was randomly selected for each Trial ($l_1 = 0.10, 0.15, 0.20, 0.25, 0.30$).
\end{enumerate}
Despite the presence of visual feedback, the Concurrent and Terminal feedback groups viewed very similar interfaces to that of the Control Group, see Figure~\ref{figure:label2}.
The Concurrent Feedback group's feedback appeared on the cursor itself (see Figure~\ref{figure:label2}b), while the Terminal Feedback group saw their visual feedback appear on the edge of the screen in the direction they commanded (see Figure~\ref{figure:label2}c).
An illustration of a potential signal input over time, along with an example of the feedback that would be presented for the two augmented feedback groups, is available in Figure~\ref{figure:label1}.

\begin{figure}[b!]
	\centering
	\includegraphics[width=.6125\textwidth]{figures/EMG/Figure2}
	\caption[Cursor interfaces]{Cursor interfaces for a) the Control and Adaptive Threshold, b) Concurrent Feedback and c) Terminal Feedback groups (not to scale).
		The feedback displayed in c) indicates the ``up'' command.
		Concurrent Feedback and Terminal Feedback groups see their respective displays when the feedback is activated, otherwise like a).
		The target is shown in green and the cursor is the other, smaller circle.}
	\label{figure:label2}
\end{figure}

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/Figure1}
	\caption[Illustrative signal input over time]{Illustrative signal input over time.
		a) The first two inputs select the command; the black bar represents the command time.
		The third input causes motion.
		The shaded areas indicate when the signal crosses the minimum threshold, $l_1$.
		b) Visual feedback is presented according to the bars (blue = Concurrent Feedback, orange = Terminal Feedback).}
	\label{figure:label1}
\end{figure}

Subjects completed 3 Code Accuracy Tests and 16 Blocks of testing during the experiment, see Figure~\ref{emg:experimentaldesign}.
The Code Accuracy Test was designed to evaluate subject's ability to enter commands, and each Test consisted of 20 randomly ordered commands (5 of each of the 4 commands).
The 16 Blocks were split into 12 Training Blocks, during which time the separate training methodologies were applied, and 4 Evaluation Blocks, during which time all subjects were exposed to same interface as the Control group.
Each Block consisted of 10 cursor-to-target trials, after which subjects completed the workload and trust surveys and had a 30 second break.

\begin{figure}[bt!]
	\centering
	\includegraphics[width=\linewidth]{figures/EMG/Figure3}
	\caption[Experimental design flowchart]{Experimental design flowchart.}
	\label{emg:experimentaldesign}
\end{figure}

\section{Analysis and Hypotheses}
This experiment investigated the effect of training methodology on performance, workload, and trust.
The primary performance metric was the percentage of successful trials in a Block, and secondary metrics were the average trial time of successful trials and the throughput.
While a majority of the our metrics are analyzed by Block, trial time was analyzed by Session as the randomization of the 40 target positions occurred over 4 Blocks.
Trust and workload were each measured using surveys.
Trust was evaluated using \citeauthor{jian_foundations_2000}'s twelve statement questionnaire which measures trust between people and automated systems~\citep{jian_foundations_2000}.
Perceived workload was measured using Modified Bedford scale~\citep{roscoe_subjective_1990}.
These surveys were administered after each Block.
We also analyzed the results of the Command Accuracy Test, which was completed prior to training, after training, and after the retention phase at the end of the experiment.
During the Command Accuracy Test, subjects were asked to input each of the four commands 5 times, and the percentage of successful inputs was used as a metric of performance.

\subsection{Hypotheses}
Based on our prior experience with augmented feedback and sEMG cursor control, we formed the following hypotheses.

\begin{enumerate}
	\item During the training phase, the Concurrent Feedback group will have the highest performance followed by Terminal Feedback, then Control, and finally the Adaptive Threshold groups.
	\item All groups will perform similarly in the retention phase.
	\item The Concurrent Feedback and Terminal Feedback groups will have a high level of trust during training with some decrease during retention.
	      Although, the trust level will still remain high during retention.
	\item The Control group's trust will continually increase.
	\item The Adaptive Threshold group will have lower trust during training, which will increase in retention.
	\item The perceived workload will continually decrease during the training phase for all groups with the largest decreases for the Concurrent Feedback and Terminal Feedback groups.
	\item There will be no significant difference in workload in the retention phase for all groups.
\end{enumerate}

\section{Results}

We ran two-factor mixed models to investigate changes in performance, workload, and trust with one between-subjects factor, Group, and one within-subjects repeated measure, Block.
When significant effects were observed, post hoc comparisons using the Tukey Honest Significance Difference (HSD) test were performed and considered significant at the $p < 0.05$ level, and the Satterthwaite method was used to calculate the degrees of freedom.

\subsection{Performance Metrics}
The percent success metric measured the percentage of successfully completed Trials within a Block; a Block contained 10 Trials.
There were significant main factors of Group ($F(3, 44) = 8.18, p < 0.001$) and Block ($F(15, 660) = 31.80, p < 0.001$).
There was also a significant interaction effect between Group and Block ($F(45, 660) = 3.90, p < 0.001$).
Despite the presence of an interaction effect that resulted from subjects learning the task (as indicated by the Block factor), the main effect of Group could still be interpreted.
A Tukey test showed that the subjects in the groups differed significantly, with subjects in the Concurrent Feedback group performing significantly better than those in the Control group ($p = 0.020$).
The Tukey test also showed that subjects in the Adaptive Threshold group performed significantly worse than those in the Terminal Feedback and Concurrent Feedback groups ($p < 0.001, 0.01,$ respectively).

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/PercentSuccess}
	\caption[Percent success by Block across groups]{Percent success by Block across groups.
		The vertical dashed line represents the transition from the training phase to the retention one.
		Error bars shown are the standard error of the mean.}
	\label{figure:label3}
\end{figure}

The interaction effect resulted from different learning rates between the groups (see Figure~\ref{figure:label3}), where subjects learned in the following order (fastest to slowest): Concurrent Feedback, Terminal, Control, and Adaptive Threshold.
Compared to the Control group, the Concurrent Feedback group significantly outperformed them for the first 6 Blocks.
Unlike the Concurrent Feedback group, the Terminal Feedback and Adaptive Threshold groups started with the same initial performance as the Control group.
The Terminal Feedback group learned more quickly than the Control group, however, and significantly outperformed the Control group for Blocks 4 and 5.
Compared to the Control group, all groups performed at statistically similar level after Block 6.
Investigating the immediate retention effects when the group-specific treatments are removed in Block 13, the mixed model showed no change in performance for any of the groups ($p > 0.99$ for all groups).
As such, the percentage of successfully completed Trials did not show any effect from the guidance hypothesis (i.e. the subjects did not rely on the feedback to complete the task and removing the feedback did not result in decreased performance).

The throughput was calculated for the retention phase and averaged across Blocks 13 through 16 (i.e. Session 4).
Throughput is generally used to assess an input device, which should be measured when the subjects can complete the task.
Since there were no significant differences in the retention phase for percent complete, it was logical to only calculate throughput at this time.
There was no significant difference in throughput between the Groups ($F(3, 44) = 1.62, p < 0.20$).
The mean throughput for all subjects was found to be 0.56 $\pm$ 0.02 bits/s ($\mu\pm\sigma$).

The randomization of the 40 target positions occurred over 4 Blocks, thus it seemed appropriate to average Trial time over a Session (i.e. set of 4 Blocks).
Trial time was only defined for successfully completed Trials, and the Satterthwaite method was used to calculate the adjusted degrees of freedom using the lmerTest package in R~\citep{RN53}.
The results are displayed in Figure~\ref{figure:label4}.
There were significant main factors of Group ($F(3, 43.97) = 4.39, p < 0.01$) and Session ($F(3, 131.07) = 24.91, p < 0.001$).
The interaction effect between Group and Session was not significant ($F(9, 131.07) = 0.78, p = 0.63$).
A Tukey test showed that the Concurrent Feedback group performed significantly better than those in the Adaptive Threshold group ($p = 0.004$), which was the only significant difference between groups.
No groups significantly outperformed the Control group.
Analysis of the Session factor showed increased performance ($p < 0.05$) until the last two Sessions, which were not statistically different ($p = 0.65$).
These results further supported that the guidance hypothesis did not occur.

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/TrialTime_session}
	\caption[Average Trial time by Session across groups]{Average Trial time by Session (sets of 4 Blocks) across groups.
		The vertical dashed line represents the transition between the training and evaluation phases.}
	\label{figure:label4}
\end{figure}

\subsection{Trust and Perceived Workload}
The Modified Bedford Workload metric is a subjective measurement of perceived workload that ranges from 1-10, where 1 indicates low workload and 10 indicates high workload.
There was a significant main factor of Block ($F(15, 660) = 18.29, p < 0.001$), but Group was not found to be significant ($F(3, 44) = 2.16, p = 0.106$).
There was also a significant interaction effect between Group and Block ($F(45, 660)= 1.82, p = 0.001$) (see Figure~\ref{figure:label5}).
The interaction effect resulted from subjects reporting lower workload as they learn the task at different rates, as indicated by the Block factor.
In further investigation of the interaction, we observed that the Adaptive Threshold group reported a significantly higher workload than the Concurrent Feedback group for Blocks 9, 10, and 11.
This perception of high workload may possibly have resulted from the significantly worse performance of the Adaptive Threshold group.
None of the groups showed a significant difference in workload compared to the Control group and all four groups reported statistically similar workloads in the retention phase.

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/ModifiedBedfordWorkloadScore}
	\caption[Modified Bedford Workload Score by Block across groups]{Modified Bedford Workload Score by Block across groups.
		The vertical dashed line represents the transition from the training phase to the retention one.
		Error bars shown are the standard error of the mean.}
	\label{figure:label5}
\end{figure}

Intragroup changes in workload were also of interest.
The Concurrent Feedback group showed no statistically significant changes in performance between Blocks, though they did demonstrate a nonsignificant, increasing workload trend in the retention phase of the experiment.
The Terminal Feedback group had statistically higher initial workload for Blocks 1, 2, and 3, but the remainder of the Blocks had a statistically similar level of workload.
The Control group's workload was significantly higher for Blocks 1-6, possibly due to their slower learning rate, but leveled off for the remainder of the Trials.
Finally, the Adaptive Threshold group reported the highest workload in Blocks 1-5, but also saw the largest improvement transitioning into the retention phase where their $l_1$ threshold stabilized to the same fixed value as the other groups.

Trust was measured using Jian's twelve question trust survey~\citep{jian_foundations_2000}.
Each question was rated on a 7-point Likert scale, the five reverse coded questions were reversed, and the results were averaged to create a single trust score (see Figure~\ref{figure:label6}).
There was a significant main factor of Block ($F(15, 660) = 13.05, p < 0.001$), but Group was not found to be significant ($F(3, 44) = 2.59, p = 0.065$).
There was also significant interaction effect between Group and Block ($F(45, 660) = 2.00, p < 0.001$).
The significant main effect of Block showed a gradual increase in trust throughout the duration of the study.
After investigating the interaction effect, we saw that no group reported a significantly different trust level than the control group on any Block, but that the Adaptive Threshold group recorded a significantly lower trust than the Concurrent Feedback group on Blocks 3-6 and 9.
Similar to workload, the primary interaction effects appeared driven by intragroup differences.
The Concurrent Feedback group showed no statistically significant changes through the study, the Terminal Feedback and Control groups displayed significant increases in trust in Blocks 1-6, and the Adaptive Threshold group reported significantly higher trust in the retention Session than during early Blocks.

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/TrustScore}
	\caption[Trust Score by Block across groups]{Trust Score by Block across groups.
		The vertical dashed line represents the transition from the training phase to the retention one.
		Error bars shown are the standard error of the mean.}
	\label{figure:label6}
\end{figure}

\subsection{Command Accuracy}
In contrast to previous results, the results in this section are not reported by Block or Session.
The Command Accuracy Test occurred three times (before Block 1, after Block 12, and after Block 16), and the average was calculated for each Test.

In each Command Accuracy Test, subjects responded to prompts to perform commands.
The command accuracy percent indicates the percentage of the 20 prompts in each Test that subjects correctly performed.
Results were averaged by group (see Figure~\ref{figure:label7}).
There was a significant main factor of Test ($F(2, 88) = 108.48, p < 0.001$), but Group was not significant ($F(3, 44) = 2.63, p = 0.06$).
The interaction effect between Group and Test was not significant ($F(6, 88) = 0.82, p = 0.55$).
Investigation into the Test variable showed that subjects performed significantly better between Test 1 and 2, and between Test 1 and 3, but not between Test 2 and 3.
These results demonstrated that there was a significant improvement in the percent of commands accurately entered after the training portion of the experiment was finished.

\begin{figure}[bt!]
	\centering
	\includegraphics[height=.4\textwidth]{figures/EMG/CodeAccuracySuccess_session}
	\caption[Command Accuracy results by Test across groups]{Command Accuracy results by Test across groups.
		Test 1, 2, and 3 occurred prior to the training phase, after the training phase, and after the retention phase, respectively.}
	\label{figure:label7}
\end{figure}

\section{Discussion}
The study results elucidated a relationship between performance, workload, and trust that was influenced by the training methodology.
The Concurrent Feedback group started with the highest performance, lowest workload, and highest level of trust.
By the 5th Block, the Terminal Feedback group overlapped with the Concurrent Feedback group in terms of percent success, workload, and trust.
These two groups then tracked each other for the remainder of the study.
The Concurrent Feedback and Terminal Feedback groups did not have significantly different average trial times throughout the study.
The initial learning of these two groups differed with the Concurrent Feedback group demonstrating high performance with smaller, incremental gains and the Terminal Feedback group with larger Block-to-Block improvements.
The Control and Adaptive Threshold groups did not appear to reach a performance plateau for the percent success and steadily improved in subsequent Blocks.
Interestingly, the trust score also continually increased for both the Control and Adaptive Threshold groups.
Although the changing cursor dynamics in the Adaptive Threshold group does not seem to adversely affected trust compared to the Control group, the Adaptive Threshold group did report a significantly higher perceived workload for Blocks 9-12---the last four Blocks in the training phase.
Once the cursor dynamics stabilized, the perceived workload in the Adaptive Threshold group was not statistically different from the other groups.
These results suggested that visual feedback led to earlier performance gains with improvements in trust and workload.
The adaptive training methodology surprisingly did not adversely affect trust, but the cost was reflected in the performance and perceived workload.
Overall, all training methodologies achieved statistically similar results during the retention phase.

Measuring performance by percent success assessed the ability to complete the cursor-to-target task in the allotted 60 s.
The average trial time provided more insight into the group's performance.
The trends in the average trial time may be explained by the Command Accuracy Test results.
Higher percentages of command accuracy tracked with lower average trial times.
This relationship was expected as less time was spent attempting to input the command when the subject was able to accurately convey the inputs.
Although there were no statistically significant differences between groups in the retention phase for these metrics, it was notable that the Adaptive Threshold group consistently performed worse than the Concurrent Feedback group.

The Adaptive Threshold group did not outperform any group in any metric during the retention phase.
The results from this group were interesting for two reasons.
Firstly, an adaptive training methodology did not appear to cause adverse effects compared to the Control group.
Unreliable automation behavior can lead to poor human-automation interaction~\citep{RN54}, but was not the case in this study.
Secondly, the benefits of increased adaption induced by uncertainty did not manifest (e.g. generalization for novel tasks).
The adaption training methodology may be better tested with a different task with the same underlying structure instead of returning to a stable condition.
For example, \citeauthor{RN36} showed that subjects trained with an adaptive training strategy were able to quickly generalize to novel tasks with similar underlying structure.
It is also possible that the cursor dynamics unpredictability was not sufficiently large compared to the inherent sEMG control noise.

Our results aligned with previously published research.
The Concurrent Feedback and Terminal Feedback groups follow the findings of \citeauthor{RN27} that augmented feedback can improve performance.
We also observed effects that may be explained by \citeauthor{RN39}'s three layer model.
At times, there were significantly different levels of trust between the groups, which indicated that the training methodologies altered situational trust.
Subjects' trust levels also increased, which supported the notion of learned trust.
While developing a brain computer interface (BCI) was not the study objective, the throughput values during the retention phase for all groups fell within published results for sEMG cursor control systems.
Our previous single-site sEMG cursor control system with 2 DOF (counterclockwise rotation and forward) reported 2.24 bits/s and 0.23 bits/s for control methodologies that used different levels of automation~\citep{RN45}.
Multi-site systems have achieved 0.84 bits/s~\citep{RN55}, 1.3 bits/s~\citep{RN56}, and 0.4 bits/s~\citep{RN57}.
The sEMG cursor control system used in this study had a throughput of 0.56 bits/s and may be of additional interest to the BCI community.
However, the purpose of the sEMG cursor control system in this study was to provide a testbed that lent itself to motor learning adaptation and was sufficiently challenging to probe the relationship between performance, workload, and trust.

The study results largely supported our hypotheses.
The percent success performance during the training phase followed the order of Concurrent Feedback, Terminal Feedback, Control, and Adaptive Threshold, but not for all times during that phase.
All groups performed similarly in percent success during the retention phase.
The Trial completion time only supported significant differences between the Concurrent Feedback and Adaptive Threshold groups.
The subjects' trust followed our expectations with Concurrent Feedback and Terminal Feedback having the highest levels, and the Control group continually increased.
The Adaptive Threshold group had lower trust during training, and the trust increased to the level of the other groups during retention.
The workload results also supported our hypotheses that Concurrent Feedback and Terminal Feedback groups would have the largest decrease in workload, and that all groups would have similar workload during retention.
Interestingly, the Concurrent Feedback and Terminal Feedback groups converged across performance, workload, and trust by Block 5.
This study provided insights on the relationship between performance, workload, and trust for various training methodologies, and highlighted the advantage of certain methodologies during the training phase.

% \section*{Acknowledgments}
% The authors would like to acknowledge the subjects who took part in this study, without whom this paper would not be possible.

In the greater context of this dissertation, this experiment illustrated that concurrent bandwidth feedback could effectively improve performance decrease the required learning time of a discontinuous task.
The extremely large and immediate gains in performance seen in Figure~\ref{figure:label3} mirror those that we observed in the SAFER task, see Figure~\ref{figure:saferdistance}.
Subjects in the Concurrent Feedback group were again able to immediately outperform the those in the Control and sustained this performance when the feedback was removed.
While slightly lower workload and higher trust was observed initially, this effect was not significant and faded with continued use of the system.
The Terminal Feedback group's also showed rapid performance improvement over the Control group, though this took slightly longer than with the Concurrent Feedback group and showed a larger variance in ability.
This suggests that subjects in the Concurrent Feedback group were able to use the feedback to more accurately and reliably control their EMG signal.
Optimal performance was more quickly achieved by presenting the feedback concurrently with the subject's action instead of delaying it.
