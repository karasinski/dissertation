\chapter{HARI Trade Study}

% Enabling Technologies for Deep-Space Human Spaceflight
% Human-Automation and Robotic Systems Trade Analysis


% John Karasinski
% UC Davis PhD Candidate, NASA Ames Pathways Intern

% Sherrie Holder
% Space and Mission Critical Systems, The Charles Stark Draper Laboratory

% Stephen Robinson
% Professor and Director, UC Davis Center for Spaceflight Research


% August 21, 2019


% Abstract
% Appropriate integration between automation and robotics systems and their human operators is essential for future space exploration. The Human Factors and Behavioral Performance Element of NASA’s Human Research Program requires a systematic understanding of the critical human-automation/robotic (HAR) integration, or HARI, design challenges for future space exploration. This document reports the results of a systematic assessment of the spaceflight-relevant HARI technologies and research topics addressing critical gaps in spaceflight-relevant HARI knowledge, and prioritizes the research required for successful human performance and HAR integration. We reviewed relevant literature across the past ten years and interviewed ten subject matter experts across industry and academia to investigate the current state of HARI technology, challenges facing development, the state of HARI research across a wide range of fields, and opportunities for advancing the state of the art through directed research. This information was used to identify relevant HARI technologies and research topics, as well as factors to assess relative priority of HARI technologies. We worked with NASA stakeholders to weight the factors relevant to assessing HARI specific technologies. A multi-dimensional trade analysis was performed to objectively score HARI research topics and specific technologies to recommended investment priorities for NASA.  
% Table of Contents
% Executive Summary	3
% Introduction	5
% Project Background	5
% Background Research	7
% Literature Review	7
% Interviews with Subject Matter Experts (SMEs)	14
% Trade Analysis	20
% Factor Assessment with NASA Stakeholders	20
% Trade Study Approach	23
% Results	24
% Research Topics	24
% Technologies	26
% Contribution (Relation to NASA HARI Gaps)	27
% Recommendations	28
% References	30
% Appendix A: Trade Analysis Tables	33
% Appendix B: Subject Matter Expert Summary of Backgrounds	38
% Appendix C: Annotated Bibliography	38

%  
% Executive Summary
% This investigation focused on a systematic assessment of current and upcoming human automation/robotic (HAR) integration, or HARI, technologies and research topics. Analysis was focused on research and technology that address critical gaps in spaceflight-relevant HARI knowledge, and prioritizing the research required for successful human performance and HAR integration. This is essential for NASA’s Human Factors and Behavioral Performance Element to understand the critical human-automation/robotic integration design challenges for future space exploration. A multi-dimensional trade analysis was performed to objectively score HARI research topics and specific technologies resulting in recommended research priorities for NASA investment. A series of factors informing overall return on investment potential were used in weighted analysis of each technology. Factors included characteristics such as TRL and applicability to relevant spaceflight tasks. While these factors for assessment pertained directly to HARI technologies, research topics were assessed through direct relationships with those technologies (Figure 1).

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figure1.png}
%         % \caption{Top-level trade study approach used in the HARI analysis}
%         % \label{figure:}
%     \end{center}
% \end{figure}
% To understand the HARI trade space, we reviewed relevant literature across the past ten years and interviewed ten subject matter experts (SMEs) across industry and academia to investigate the current state of HARI technology, challenges facing development, upcoming automation/robotic technologies across a wide range of fields, and opportunities for advancing the state of the art through directed research. Based on the gathered information, we derived a list of HARI research topics essential to addressing HARI development challenges and advancing the state of the art, as well as a list of specific HARI technologies with application toward HAR tasks common to either long duration deep space exploration (orbital) missions, space surface exploration missions, or both. An initial set of factors for assessment of technologies was developed. These factors were characteristics of technologies that effect the potential impact of development on NASA missions, or overall return on research investment. Factors included HAR task applicability, task (capability) enabling, potential to reduce or introduce risk, and Technology Readiness Level (TRL), among others.

% Factors were provided to a group of NASA HARI stakeholders from NASA Ames Research Center and NASA Johnson Spaceflight Center. They were asked to review eight factors and rank them from most important to least important for consideration of HARI technology investment potential. NASA stakeholders were informed that these factors would be weighted and used to conduct a trade study designed to help NASA prioritize which technologies and, consequently, which HARI research topics, should be pursued in support of future long duration exploration missions. After gathering their input, the stakeholder’s scores of the factors were averaged and ranked. The final ranks were used in our trade analysis.

% A multi-dimensional trade analysis was performed to objectively assess HARI research topics and specific technologies. The factors for assessment were traded directly with HARI technologies, while research topics were assessed through direct relationships with those technologies. Technologies were first assessed against each factor in a series of individual one-dimensional trade analyses (each trading technologies against one factor). The results of these factor-level trades were normalized and used to score technologies, taking into account the relative factor weights, in the factor-to-technology dimension of the larger analysis (Figure 1). The research-topic-to-technology dimension was assessed based on relationships between the two. Research topics and technologies were defined as related if a given technology supports the research topic such that its development would fundamentally drive investigation of that topic. The scores for each related technology for a given research topic were summed to achieve the total score for that topic.

% The top-ranking research topics were: (1) Improving training for HAR systems and tasks, (2) Establishing appropriate trust in automation/robotics systems, and (3) Understanding human intent. The top-ranking technologies identified from the trade study were: (1) Machine Learning, (2) Autonomous obstacle detection/imaging, (3) Robotic/human information interfaces, and (4) Artificial Intelligence. These results reflect the surveyed background literature and the information gathered from our SMEs. These top-ranking research topics were driven by their associated highly scoring technologies, while the top-ranking technologies have seen enormous advancements in research interest and development over the past few years, and all offer a large benefit to the tasks required by NASA on future missions. The top-ranking technologies all benefited from high marks across all factors.

% Based on the trade analysis performed, it is recommended that NASA prioritize research investment in the topics of improving training for HAR systems and tasks, establishing appropriate trust in autonomous/robotic systems, and understanding human intent. These top-ranked research topics can be traced to trends of broad task applicability, high potential for risk reduction, low potential for risk reduction, and are areas whose study supports the advancement of research in lower-ranked topics as well. Investigation of these research topics will provide a fundamental foundation for addressing challenges that face implementation of HARI technology solutions in future exploration missions. 

\section{Introduction}
Technological advancements in automation and robotics necessitate appropriate integration between these systems and their human operators. To date, there has not been a systematic evaluation of the HARI design challenges for human spaceflight critical to current and upcoming automation/robotic technologies. Industries like transportation, air traffic management, and defense are investing significant time and effort to investigate and solve the many design challenges involved in human-automation/robotic integration. NASA’s Human Factors and Behavioral Performance Element needs to understand the critical human-automation/robotic integration design challenges for future space exploration. A survey of the upcoming research topics and technologies which can be applied to NASA from a range of industries and domains is needed in order to reduce the risks associated with human spaceflight.

Therefore, an assessment of the upcoming technologies and open research challenges critical to effective human and automation/robotic integration (HARI) systems across industries and domains is essential to inform the design and development of safe, efficient future systems. The objective of the current project is to conduct a systematic assessment of the space-relevant HARI automation/robotic technologies in order to prioritize necessary research required for successful human performance and HAR integration. This includes identification of aspects that influence the relative importance of technology for spaceflight, or factors, for assessing prioritization of HARI related research and technologies.

% Project Background
% The overall objective of this study was to investigate HARI technologies on the horizon with the potential to support critical HAR tasks and use trade analysis to assess these technologies against critical factors for investment in order to determine recommendations for research and development. The project was designed with two Phases, with Phase 1 focused on gathering background information and identification of specific technologies, and Phase 2 focused on trade analysis. Tasks were originally proposed for each Phase as shown in Table 1. This project largely followed the original two-phase plan, with background research informing the design of a trade study aimed to provide recommendations of technologies/research to pursue. However, specific tasks were redirected, in coordination with the Human Automation / Robotics Integration (HARI) Discipline Scientist (DS) (NASA Civil Servant at Ames), as we gathered the background information in Phase 1 and learned more about the trade space.

% In exploring HARI technologies and risks and challenges facing development, as described in the Phase 1 tasks, through literature review and interviews with Subject Matter Experts (SMEs), it became evident that technology implementations as described in Task 1.3 would vary widely due to dependence on specific mission design, even when constrained to a specific HAR task. It would not be possible or practical to capture the space of all possible specific technology implementations at such a detailed level. The primary goal of this project was to explore a trade space of HARI solutions or directions for research, not to trade on mission designs. Rather than explore a subset of implementations whose applicability to a HAR task would be limited mission to mission, we chose to raise the level of the technology/research trade space and explore broader solutions to HARI challenges as they apply to HAR tasks common to the scope of long duration orbital and planetary surface exploration missions. For example, exploring the potential of Augmented Reality/Virtual Reality (AR/VR) technology in general as applied to HAR tasks, as opposed to a specific implementation of AR/VR to train for surface operations that assumes a human-robot team makeup (a mission design decision).

% In reviewing a draft of the report described in Task 1.5, it became apparent that the HARI solutions identified fell into two categories. While some were technologies which support or enable HAR tasks, others were research topics related to those technologies whose study will fundamentally drive future HARI capabilities and directly address HARI challenges. Given the importance of the research topics identified for addressing HARI risk, the trade analysis plan was directed to capture both technologies and research topics (and the relationship between them). Additionally, with each technology and research topic applicable to a range of HAR tasks as described above, rather than having a separate analysis for each task, HAR task became a critical factor for comparison across the trade space, providing a more complete evaluation between technologies. Although the process outlined in the Phase 2 tasks was followed, the focus of the trade analysis was shifted to reflect the nature of the trade space. This shift allowed the study to produce relevant recommendations on closing HARI risk as intended.

% Phase 1
% Task	Task Description
% 1.1	Work with the Human Automation / Robotics Integration (HARI) Discipline Scientist (DS) (NASA Civil Servant at Ames) to understand the HAR tasks and the key mission architecture design constraints that will heavily influence future HAR system design.
% 1.2	Identify and consider current and near-term future (expected to be operational within the next 10 years) HAR classes of technologies and capabilities that are relevant to the required HAR tasks.
% 1.3	Identify possible technological implementations, i.e., automation and robotic systems, to accomplish these HAR tasks, taking into account the mission architecture design constraints in the Concept of Operations.
% 1.4	Determine the associated HARI design and research challenges associated with each HAR technological solution.
% 1.5	Coordinate with the HARI DS and develop a report describing the potential technologies and associated risks and challenges of each.

% Phase 2
% Task	Description
% 2.1	Develop draft criteria and associated weighting for the trade space evaluation of the suitability of each class of technology for each relevant mission task. Among potential decision criteria are: technology readiness, safety-criticality, crew-time savings, unique capability, and minimum frequency of interaction between the human and automation/ robotic system.
% 2.2	Work with the HARI DS and other NASA stakeholders to arrive at a consensus for criteria and relative weighting, by participating in a series of virtual meetings, an on-site workshop, or technical interchange meetings as organized and implemented by NASA and KBRwyle.
% 2.3	Develop an analysis method for applying the DS-agreed upon criteria to evaluate each technology for each DRM task, be it computationally
% modeled, empirically data driven or based on subject-matter expertise.
% 2.4	Complete the trade analysis using the selected analysis method and criteria, and develop recommendations for the most likely automation/ robotic implementations; identify the corresponding human integration design challenges associated with developing each HAR
% system.
% 2.5	Develop and deliver a final report on the findings, which will include recommendations for each of the HAR tasks.
% Table 1: Tasks initially proposed for Phases 1 and 2 of the HARI Trade Analysis

\section{Background Research}
To begin the assessment of space-relevant HARI critical factors, we first completed a comprehensive literature review of the field of human and automation/robotics interaction. Background literature primarily focused on survey papers from the past ten years, but also included prominent papers from noted authors in the field. Primary research was also gathered from discussions with subject matter experts in human factors and human-robot interaction related fields. Findings and lessons learned from this investigation are provided in this report.

\subsection{Literature Review}
We completed a review of human factors and automation/robotics integration survey papers published over the past decade, with an increased focus on the past five years. Non-survey papers from highly cited and established experts were also added to this review to provide additional insights. When reading these papers, care was taken to note recurrent topics and technologies that received specific focus, were forecast to generate additional interest in the near future or were otherwise noted as requiring greater study.

As a result of this literature review, major themes of in human and automation/robotic integration technology development and research were identified, see Table 2.

% 	Machine Learning	Flexible/
% Adaptive/
% Adaptable Automation	Networked Multi-robot Systems, Swarms	Trust
% Admoni and Scassellati, 2017 [1]
% 			x
% Ahmad et al., 2017 [2]
% x	x
% Chen and Barnes, 2014 [3]
% x	x	x
% Endsley 2017 [4]
% x	x		x
% Guiochet et al., 2017 [5]
% 			x
% Kehoe et al., 2015 [6]
% x		x
% Kolling et al., 2016 [7]
% 	x	x
% Liu and Wang, 2018 [8]
% x
% Losey et al., 2018 [9]
% x	x		x
% Lu et al., 2016 [10]
% 	x
% Ososky et al., 2013 [11]
% 		x	x
% Parasuraman and Wickens, 2008 [12]
% 	x
% Phillips et al., 2016 [13]
% 			x
% Rautaray and Agrawal, 2015 [14]
% x
% Schaefer et al., 2016 [15]
% 			x
% Sheridan, 2016 [16]
% x			x
% Vagia et al., 2016 [17]
% 	x
% Wang et al., 2018 [18]
% x		x
% Zamora et al., 2017 [19]
% x
% Table 2: Table of the key papers reviewed, and the topics discussed in each

Each of these topics is briefly discussed below, referencing their fundamental papers when possible, as well as their forecasts from the previously reviewed articles.

\subsubsection{Machine Learning}
Machine learning (ML) is among the most commonly mentioned topics which authors forecast as being essential to the future of human-robotic interaction [18]. Machine learning has enabled significant benefits in a variety of automation/robotics systems but has also given rise to the need for explainable systems and has raised additional questions about trust. While machine learning techniques may be effective, they are rarely easily explainable, and operators often have difficulty understanding exactly why a system behaves as it does. Additionally, as these systems have become more sophisticated, they have become able to continuously learn and update their behavior, making it challenging for operators to maintain both system understanding and appropriate levels of trust [3].

Machine learning techniques such as hidden Markov models, Gaussian mixture models, and radial basis function neural networks, though usually requiring a supervised training phase, have been shown to be very effective in predicting human intent in the context of physical human-robotic interaction [9]. In reviewing which machine learning algorithms are currently being used, Zamora et al. found that neural networks accounted for an overwhelming majority, but that both supervised and unsupervised algorithms were about equally common [19]. ML is essential to the fields of vision-based hand gesture recognition and non-visual gesture recognition, without which gesture recognition devices would be impossible [8], [14], [20]. As computer technology continues to rapidly advance, the ability to detect, track, and classify gestures in real-time has enabled this technology to be implemented in manufacturing and other industrial plants. Liu et al. specifically call out a need to combine different ML algorithms to improve efficiency, and that deep learning techniques are now enabling non-wearable sensors [8]. ML has also been used to vary the personality and behavior of adaptive social robots [2].

In her 2017 paper, Endsley noted the research needs for the next thirty years of designing and building fully autonomous systems [4]. Several of these specifically concern machine learning techniques, including validating autonomy software, learning system consistency and transparency. There are currently no effective techniques for validating autonomy software, as "traditional methods fail to address the complexities of learning systems. Exhaustive testing of rules and potential system states will not be possible and understanding boundary conditions will be difficult" [4]. Validating machine learning solutions is currently an active area of research. There is concern about consistency in learning systems, as different systems will learn using different techniques and provide different levels of feedback about how their automation has changed based off new data. Endsley notes the lack of transparency in learning systems as a unique challenge, saying "[t]he actual logic and lessons 'learned' by neural networks and deep learning software are typically opaque not only to the human operator but also to software developers who may not fully understand how the system will behave in all circumstances" [4]. These problems are exemplified by Sheridan, who notes that "[i]t is becoming clear that many complex traffic situations are exceedingly difficult for computer vision and artificial intelligence to 'understand' and that many accidents are avoided by social interaction between drivers, such as mutual eye contact, hand signals, and so on. Understanding the social aspects of driving in traffic, as well as the degree to which cars can be safely automated, demands much further research" [16].

\subsubsection{Flexible, Adaptive, or Adaptable Automation}
Flexible, adaptive, and adaptable automation are widely praised in the literature for their ability to provide dynamic levels of automation. The flexibility to provide different sets of automated features during different mission phases, for instance, is an effective requirement for many modern tasks. One example of this is the autopilot software used in modern transport aircraft, which includes multiple modes of automation for takeoff, cruise, and landing. Chen and Barnes define flexible automation as "systems that invoke various levels of automation depending on the operator’s state, critical events in the environment, or algorithms related to specialized problem sets" [3]. Chen and Barnes and others have subdivided flexible automation into subtypes, based on the involvement of humans in the decision making process: adaptive automation—where tasks are assigned using conditions established before a mission, adjustable automation—where the human decides when to invoke automation, and mixed-initiative systems—where both the human and the system jointly decide how to allocate tasks [3], [21]. These dynamic changes in the role of the human in the human-automation interaction are meant to "either increase the robot’s level of autonomy at the expense of the human’s authority, or, conversely, increase the human’s control over the shared cooperative activity at the expense of the robot’s autonomy" [9]. These systems help maintain overall performance while attempting to reduce workload and maintain situational awareness for their human operators [22].

Among these three automation technology areas, adaptive automation has seen the most research, and many authors have involved it in empirical studies [17]. The primary difficulty with adaptive automation lies in "thorny human factors issue of [function] allocation...which has been met with marginal success" [17]. Optimal assignment of tasks between the operator and the system is difficult as it requires excellent understanding of the performance of the operator and the system's response to the operator. It also requires the operator to be fully aware of the functional allocation at all times, otherwise mode confusion may occur.

Flexible automation can react to dynamic changes in the environment, and researchers have been able to include real-time sensor data of human physiological states to bring the operator's workload and situational awareness into the loop. Monitoring the human allows the system to automatically take over tasks when workload is high, and has been used to send control back to the human when the system notes that they have become complacent or as an attempt to increase situational awareness [10]. This type of automation is already present in self-driving vehicles on the road today—self-driving vehicles require that drivers have their hands on the wheel even when in self-driving/lane-keeping modes. While this flexible automation is often effective in common and well understood systems such as driving, there is some concern that flexible automation may prove detrimental in complex and potentially unpredictable systems such as robotic swarms [7].

While adaptive and adaptable automation has been the subject of many experiments over the past few decades, the question of who should be in charge of setting the level of automation remains an open question in need of further study, though mixed-initiative systems may provide the best of both worlds [3], [12]. Chen and Barnes conclude their review by noting that "[m]ixed-initiative architectures take advantage of the synergy between the more sophisticated worldview of an experienced human as well as the agent’s logical precision and more rapid latencies" [3]. This architecture is inherently complex and difficult to study, however, as individual differences such as age, expertise, and trust have large effects when interacting with these systems [15]. Further research is recommended into different types of flexible automation, especially when it deals with very complex systems.

\subsubsection{Networked Multi-robot Systems and Swarms}
Human automation/robotics interaction has traditionally focused on a single robotic system, but the miniaturization of computer technology has made swarm or multi-robot systems an increasingly viable option. The ability for swarms to dynamically reconfigure themselves in response to changing environmental variables and task demands, however, can lead to complex requirements on the human operator. There remain important questions to be answered in the realm of human systems integration with swarms, especially regarding human supervisory control [7]. There is a specific concern with monitoring human workload and situational awareness as the number of robots increases. Depending on the number and ability of robots and the type of tasks being performed, it is possible to quickly overburden the swarm operator, especially when operator is required to negotiate swarm-swarm interactions. Kolling et al.’s 2016 review breaks the cognitive complexity of the human-robot system into three complexities: robots performing independent activities, with complexity O(n), which allows more robots to be controlled simply by adding more operators in a linear manner; robots interacting with other robots fully autonomously, with complexity O(1), which allows for a fixed number of robots to control any number of robots; and the case where robot-robot interaction must be controlled by an operator, with complexity O(>n), as the dependencies between robots results in more demand faster than the number of robots grows [7]. See Figure 2 for a graphical illustration of control complexity under each of these conditions.

\begin{figure}[b!]
    \begin{center}
        \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figure2.png}
        \caption{Graphical illustration of the concept of control complexity in a human–multirobot system [7]}
        % \label{figure:}
    \end{center}
\end{figure}
Ongoing research into human-swarm interaction and multi-robot systems has primarily focused on coordinated swarm control, changing swarm topology, and describing the state of the swarm in a more understandable way [18]. The development and design of human-swarm interfaces for multi-robot collaboration and, particularly, unmanned aerial vehicle teams is another important set of ongoing research. The ability for swarms to multitask, and the requirement for the human operator to quickly task switch has been shown to cause detrimental effects on overall system performance [3]. High workload phases have been shown to be most sensitive to interruptions from tasks switching, suggesting that task switching should be avoided during these phases unless absolutely necessary [23]. Issues relating to multitasking, task switching, and the loss of situational awareness can be mitigated with properly designed human-swarm interfaces. Chen and Barnes outlined several of the prominent issues in user interface design and offered solutions in the form of guidelines [3]. They identified six issues range from "maintaining operator's ultimate decision authority" to "visualization and training techniques enhance human-agent collaboration", and present guidelines based on the findings of their review.

The concept of robots and automation systems that rely on externally networked support has also been explored by researchers [6]. New topics of research using "the cloud" or otherwise networked robotics include big data, cloud computing, collective robot learning, and human computation, see Figure 3. Other key technologies which can be enhanced with networked robotic systems include human-robot collaboration technology, autonomous navigation technology under non-structured environments, multi-agent robot systems (swarms), and emotion recognition and interaction mechanism of robot oriented to harmonious human-robot cooperation [18]. Issues associated with the rise in cloud technology include the need for techniques to consider time varying latency and quality of service, system security from remote intrusion, privacy concerns, and big data cleaning and filtering techniques. Currently, cloud computing can be described as a framework with consists of three levels: Infrastructure as a Service (IaaS), where bare operating systems are available; Platform as a Service (PaaS), where more structure is provided, including access to application frameworks, databases, and programming languages; and Software as a Service (SaaS), where software is made available online rather than as a local service [6].

\begin{figure}[b!]
    \begin{center}
        \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figure3.jpg}
        \caption{Combining Robotics, the Internet of Things, and Cloud computing has resulted in many new possibilities such as Cloud Robotics [24]}
        % \label{figure:}
    \end{center}
\end{figure}

\subsubsection{Trust}
Human trust has numerous definitions but for our purposes can be considered to be “the attitude that an agent will help achieve an individual’s goals in a situation characterized by uncertainty and vulnerability” [25]. Trust has become an increasing topic of research as robotics increasingly moves out of traditional settings such as manufacturing and into more common-place locations such as the office and the home. Trust has a large impact on the physical safety of people operating around robots, as improper trust can lead a person to inadvertently place themselves in harm’s way. Considering the ways that trust changes over time has been an important aspect of the research into trust, and Schaefer et al. define trust as a three-dimensional expression of a relational property:
	An individual's overall, long-term propensity to trust in general
	A transient, momentary trust responsive to immediate ambient conditions
	How 1) and 2) evolve over time [15]
Their meta-analysis found strong effects between human-robot interaction and analyzed the factors that determine trust. A robot or robotic system's ability to garner trust relies on several factors. See Figure 4 for Schaefer et al.'s conceptual organization of influencing the development of trust. Trust is commonly assessed using surveys, many of which have been proposed, which attempt to measure the individual factors which establish trust. These scales attempt to measure individual elements of trust, asking about the operator’s assessment of the automation’s competence, predictability, and dependability, among other factors. Of these measurement techniques, two of the most commonly used scales are the “Checklist for Trust between People and Automation” [26] and versions of Muir and Moray’s subjective rating scales [27], though research into real-time techniques is ongoing [28]. Appropriate trust is important when shared control between human-robot teams is essential, as the human is more likely to arbitrate additional tasks to the robot when this trust is established [9].

\begin{figure}[b!]
    \begin{center}
        \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figure4.png}
        \caption{A conceptual organization of trust influences highlighting trust development [15]}
        % \label{figure:}
    \end{center}
\end{figure}

Ososky et al. made several propositions regarding human trust of robotics, among the most important being that:
	Humans are easily influenced by superficial characteristics of robots
	Human subjective assessment of trust in robots ultimately determines the use of robotic systems [11]
They noted that robot characteristics had the strongest influence on trust in human-robot teams, which included factors such as reliability, transparency, and anthropomorphic qualities. One example of this is de Visser et al.'s 2016 study, which found that anthropomorphic automation associated greater trust resilience [29]. de Visser et al. concluded their study by suggesting that designers incorporate these features into future robots as a deliberate design choice to garner greater trust. Even very simple additions such as high levels of mutual gaze have been shown to increase trust, while gaze aversions stoke feelings of distrust between human-robotic teams [1].

While anthropomorphism can lead to greater trust, some authors note caution when incorporating these features. Culley and Madhaven warn that individual differences can lead some individuals to place too great a trust in anthropomorphic robots [30]. Individuals are even more likely to trust anthropomorphic robots if they perceive similarities to the robot and themselves regarding age, gender, and even similarity of movement [31], [32]. Ososky further warns that trust in a robot's reliability alone is insufficient for better teamwork, and that over-trust combined with an inaccurate or incomplete mental model can lead to worse overall performance. This is especially important when considering changing levels of automation in the field of human-automation interaction, for example, as an operator may not fully understand what they are currently responsible for, if the robotic system is in control. This has led to numerous incidents leading to serious injury and death. Trust in human-robot teaming is slightly different than trust in automation, however, as robots are often seen as collaborating teammates rather than just an automated tool [11].

\subsection{Interviews with Subject Matter Experts (SMEs)}
In order to provide a current assessment of the critical challenges associated with effective HARI systems across industries and domains, we also interviewed subject matter experts (SMEs). SMEs were chosen to represent a cross section of HARI related disciplines such as aerospace, industrial robotics, military applications, medical, and autonomous vehicles. SMEs were intentionally selected from different backgrounds, including military research, academia, and industry (robotics, medical, aerospace), in order to provide broad perspectives on the risks and challenges facing HARI technology development, as well as HARI technology and research. We conducted ten phone interviews with SMEs who integrate humans, automation, and robotics in their work. These interviews generally took between twenty and forty minutes. We asked each expert the following questions:
	What technologies do you think are on the horizon in your field in the integration of humans, automation, and robotics?
	How would you prioritize what technologies are in development involving the integration of humans, automation, and robotics?
	What technologies would be the most responsive to increased research support?
	For these technologies, what are the current TRLs? How much effort do you think it will take to raise the TRL over time?
	What are you most concerned about for the integration of humans, automation, and robotics? What technologies do you think could mitigate these risks?
	What risks do you see arising from inclusion of these technologies (what new risks do you anticipate)?
	What risks currently have no technology solutions?
	How will these technologies fill the gaps in our current abilities?
	Where do you see additional automation as a plausible way to fill those gaps?
	What other technology gaps should we be concerned about?
	Based on this discussion, is there anything else we should know?

Based on the information gathered from literature and discussion with subject matter experts, the following specific HARI-related technologies and research topics emerged as areas for future research and development for the advancement of human automation and robotic interaction relevant to human spaceflight.

\subsection{Specific Technologies}
\subsubsection{Non-invasive behavioral and physiological sensing}
Non-invasive behavioral and physiological sensing includes a range of techniques. Some physiological sensing techniques include common place, if controversial, methods such as a polygraph, to electromyography (EMG), electroencephalogram (EEG), and electrocardiogram (EKG) sensing. Behavioral analysis techniques can include techniques that rely extensively on video analysis, such as gait analysis, and more integrated technology covering additional modalities. This technology can be used to infer team member states. The use of artificial intelligence to combine these perceptions is relatively developed. This technology has an estimated TRL range of 3-5.

\subsubsection{Implantable Biometrics}
Compared to many of the other specific technologies we identified, implantable biometrics is a relatively young field which focuses on implantable biosensors for precision and personalized medicine. These sensors can provide continuous data on specific, targeted metrics which can allow for the immediate detection of problems or need for intervention. Implantable biometrics is especially important in the "diagnosis, monitoring, management and treatment of a variety of disease conditions" and can be used to detect changes in a person’s health [33]. Further advances in miniaturization and nanotechnology are likely needed for this technology to advance further. This technology has an estimated TRL less than 3.

\subsubsection{Autonomous obstacle detection/imaging}
Autonomous obstacle detection/imaging is a combination of technologies designed to identify obstacles around a robot or other autonomous agent. Detection and imaging can make use of visual spectrum or other light sources, acoustic or magnetic sensors, or laser-based technologies such as LIDAR. Multiple techniques also take advantage of combining these technologies into multispectral sensors. These technologies are important for autonomous docking and landing of spacecraft but have also seen an enormous increase in interest from the self-driving car industry. One important side effect of increased demand of this technology in self-driving cars in the past few years is that the hardware has both rapidly miniaturized and dropped in price. Note that this technology is only concerned with detection, while resulting actions and path planning is captured elsewhere (autonomous path planning). This technology has an estimated TRL of 6 or greater.

\subsubsection{Autonomous path planning}
In contrast to autonomous obstacle detection, autonomous path planning describes the resultant planning and action that is taken after an obstacle is sensed or an objective is determined. This technology benefits greatly from a good understanding of the robot or autonomous agent's dynamics, the environment it acts in, other agents in the environment, and the objective's location. With regards to spaceflight, autonomous path planning is relevant when considering orbital proximity operations (including rendezvous and docking), surface landings, and rover movements. This technology has also seen great benefits from the self-driving car industry, especially regarding planning around other moving agents whose intent is often poorly understood. This technology has an estimated TRL of 6 or greater.

\subsubsection{Speech recognition}
Speech recognition is a set of technologies that enable the translation of spoken words to text by computer software. Speech recognition has been actively developed since the 1970s and has a generally high rate of success. Despite this relatively long period of development, recent advancements in speech recognition have been made by integrating machine learning techniques. Transforming spoken word to text allows autonomous systems and robots to accept commands or infer human intent and is a common alternative to physical computer interfaces [34]. It also allows for the detection of speech patterns and inflection classification to capture intent, trust, fatigue, or emotional states. Depending on the system and application, speech recognition systems have higher TRL in the range of 6 or greater.

\subsubsection{Intuitive control interfaces}
Intuitive control interfaces consider ways of intuitively mapping human gestures to a resultant robotic action, and often takes human physiology, kinematics, and other elements of physical movement into consideration. This technology includes interfaces types such as joysticks, keyboards, touchscreens, and gesture recognition, among others. This technology has an estimated TRL of 6 or greater.

\subsubsection{Robotic/human information interfaces}
Information displays must determine what information to transmit for any given task, which may be customized based on user preference, task or environment concerns, past experiences, or the presence of anomalies. These may include multimodal (visual, audio, and/or haptic) displays which display task relevant information to an operator. They may display 2D or higher-dimensional information and may be body-worn or mounted in the environment. These displays have elements designed by both human-computer interaction experts and machine learning algorithms. Ideally, such displays would be ubiquitous, capable of quickly and easily transferring information between stations, and able to appear on traditional monitors, tablets, smartphones, or augmented reality interfaces. While some elements are well-defined and arguably in use today, others remain in early stages of development. Based on feedback, these systems have a current overall TRL estimated at 3-5.

\subsubsection{Augmented Reality and Virtual Reality}
Augmented and virtual reality are a pair of technologies which provide a partial or fully virtual environment to a user, often in the form of a head mounted display. Augmented reality has also been developed to work with modern phones and tablets, and can provide additional, digital context to an otherwise physical object or environment. Virtual reality is increasingly used as a training tool, while augmented reality has begun to be used as a tool for both training and operations. This technology has an estimated TRL of 3-5.

\subsubsection{Robotic agents}
This technology encompasses a large variety of robots, which include rovers, satellite or UAV swarms, robotic arms, and vehicles, among others. The relative TRL varies between relatively low, in the case of robotic swarms, to very high, in the case of rovers and robotic arms. These sets of technologies enable humans to complete tasks that they could not otherwise accomplish, either because they take place in an extreme, dangerous or difficult to reach environment (as is the case with Martian rovers), they require abilities humans do not (moving payloads required by robotic arms such as Canadarm2) or because they would take too long (such as the mapping or scouting of a region by a swarm of UAVs or satellites). On average, TRL may be estimated within the range of 3-5.

\subsubsection{Assistive Robotics}
In contrast to robotic agents, which largely replace the human or do not require a human to be present, assistive robotics describe robots that directly interface with humans to assist them in accomplishing a task. These robots include small assistive satellites such as Astrobee, a modern version of the Apollo Lunar Roving Vehicle with more advanced guidance capabilities, exoskeletons, or personal assistants. These robots enhance the already existing abilities of humans by enabling them to complete tasks that they otherwise could not, or by increasing performance in challenging tasks. This technology has an estimated TRL of 3-5.

\subsubsection{Artificial Intelligence}
Artificial intelligence is intelligence demonstrated by machines, in contrast to human intelligence. Some of the major goals of AI include knowledge reasoning, planning, natural language processing, computer vision, robotics, and machine learning. In space HARI, AI could primarily be leveraged in managing complex systems (i.e. diagnostics, prognostics, and maintenance of spacecraft) and in acting as assistants for crew completing science and activity tasks. By correctly interpreting human intent, AI can also control robots for payload and physical crew assistance. This technology has an estimated TRL of 3-5.

\subsubsection{Machine Learning}
Machine learning describes a collection of algorithms which perform a specific task without using explicit instructions, instead relying on learned models. Common types of machine learning include supervised learning, in which a human trains the model, unsupervised learning, where the system learns on its own, and reinforcement learning, where the software takes actions in an environment to optimize a cost function. Machine learning has improved the performance of many varied technologies and is the foundation on which artificial intelligence is being developed upon. This technology has an estimated TRL of 6 or greater.

\subsubsection{Flexible, Adaptive, or Adaptable Automation}
As noted earlier in the report, flexible, adaptive, and adaptable automation are widely praised in the literature for their ability to provide dynamic levels of automation. The flexibility to provide different sets of automated features during different mission phases, for instance, is an effective requirement for many modern tasks. Chen and Barnes define flexible automation as "systems that invoke various levels of automation depending on the operator’s state, critical events in the environment, or algorithms related to specialized problem sets" [3]. This technology has an estimated TRL of 6 or greater.

\subsection{Research Topics}
\subsubsection{Understanding human intent}
The topic of understanding human intent is wide, and includes subtopics such as the robotic interpretation of human intent, understanding human intent unobtrusively, and improving human to robot communication. The interpretation of human intent by a computer or robot can be done in a variety of ways, including speech, gestures, and other forms of nonverbal communication. These techniques are at varied levels of development, from basic proof of concept to use in operations. Each technique can be broken down into several levels—gestures, for example, have four levels: sensor technologies, identification, tracking and classification [8]. This is area is also closely tied to interpreting behavioral and human monitoring data and encompasses human/behavioral model research such as the prediction of intent from eye movements [35], [36].

\subsubsection{Autonomous/robotic system communication to humans}
In contrast to the previous topic (understanding human intent) the research topic of autonomous/robotic system communication to humans addresses how these complex systems can best relay information back to a human operator. This topic includes both research of communication techniques and mitigation of miscommunications from the system to the human. This topic deals with discovering effective methods of providing information to a human user in an intuitive way, such that communication feels natural to a human operator. Human-robot communication is largely focused on developing multisensory methods to successfully communicate a robot’s intent to humans. Human-autonomous system communications additionally deals with methods to successfully enable explainable and transparent autonomous system operation.

\subsubsection{Ensuring human safety (physical)}
This topic captures research which investigates how to enable safe human and robot operation in a shared environment in order to reduce risk. It specifically investigates methods to successfully prevent harm to humans in close physical proximity with robots and develops guidelines and recommendations as to how physical interaction between robots and astronauts can safely occur. This research topic benefits from the lessons learned in manufacturing settings, where humans and robots must often work nearby or directly with each other, as well as that work done by autonomous car companies in avoiding pedestrians.

\subsubsection{Continuous human performance monitoring}
The topic of continuous human performance monitoring seeks to understand human-system performance and measure human performance unobtrusively. This research topic seeks to understand which human-system performance measures and limits are required for spaceflight and seeks to validate novel methods and technologies for measuring a variety of aspects of human performance such as task performance, workload, and situational awareness. Research in this area also focuses on understanding the human performance effects resulting from adaptive automation and attempts to identify what are the performance differences between adaptable (human sets level of automation) versus adaptive (automation sets level of automation).

\subsubsection{HAR team performance optimization and function allocation}
Human autonomous/robotics team performance optimization and function allocation investigates different ways of understanding human-robot teamwork and human-autonomous system robustness, decides whether a particular function will be accomplished by a person, technology (hardware or software) or some mix of person and technology [33], and how to optimize that balance [37]. This research focuses on what social and teamwork elements enable successful human-robot collaboration, especially when it requires direct interaction between robots and astronauts. With relation to robustness, this area also captures research on how to measure robustness when humans are using system in off-nominal conditions and identifying when these systems are off nominal.

\subsubsection{Enabling command/control of complex robotic systems}
This topic focuses on enabling command/control of complex robotic systems and enabling critical decision making. This includes research on methods to successfully allow humans to command and control multiple, mixed robotic agents with varying levels of autonomy and flexible function allocation. It also looks at new methods to enable humans to make time-critical decisions using autonomous systems across a variety of system dynamics and is required to evaluate methods for different autonomous systems with different functions (e.g., ECLSS vs. Power vs. Navigation).

\subsubsection{Improving situation awareness in HAR systems}
One of the most accepted definitions of situation awareness states that "[s]ituation awareness is the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in the near future" [38]. This research topic focuses on techniques to both maintain and improve operator situation awareness when interacting with automation/robotics systems. Recent work by Endsley has further expanded early models of situation awareness, discussing the emerging problem of loss of operator situational awareness and out-of-the-loop performance problems associated with increasing system autonomy, reliability, and robustness [4]. This new model for human-autonomy system oversight (HASO), incorporates situation awareness, trust, workload and automation interfaces among the key system design features influencing human cognitive processes involved in successful interaction with automated systems.

\subsubsection{Improving training for HAR systems and tasks}
The topic of improving training for HAR systems and tasks investigates what new methods are required or most effective to train humans to use complex, advanced autonomous and robotic systems. Research in this area explores different techniques and technologies to improve human performance and reduce workload, and often makes extensive use of mockups, simulations, hands-on walkthroughs, and human-in-the-loop studies. Many techniques have been explored to improve training, including many kinds of feedback, manual control adaptation, and the use of virtual and augmented reality.

\subsubsection{Establishing appropriate trust in automation/robotics systems}
This research topic focuses on techniques to establish appropriate trust in automation/robotics systems and mitigating changes in trust between humans and these systems. It explores how trust changes with factors such as communication, reliability, workload, social acceptability, privacy, and transparency. As noted earlier, it can be challenging for operators to establish appropriate trust as these automation/robotics systems become more sophisticated [3]. This research has also focused on shared control between human-robot teams and how tasks are arbitrated to the robot when trust is established [9]. Trust research investigates when there is a difference between expected and executed actions, and requirements on systems depending on whether knowledge is collected and maintained by software or by human operator.

\section{Trade Analysis}
In addition to specific technologies and research topics, the information gathered from the literature review and the discussions with subject matter experts was used to identify factors relevant to the assessment of technology or research for future investment. With all of this information gathered, the factors were refined and used in a multi-dimensional trade study to assess the technologies and research topics as priorities for HARI investment.

\subsection{Factor Assessment with NASA Stakeholders}
In addition to interviewing the human, automation, and robotics integration SMEs, we also surveyed six NASA HARI stakeholders for their input on the trade study. As NASA stakeholders involved in human, automation, and robotic interaction, we asked them to review eight factors and rank them from most important to least important in consideration of HARI technology for investment. We also had them rank additional "secondary criteria" for the factors related to risk.

Factors are characteristics of a technology that our team, in collaboration the NASA HARI DS, has identified and selected because they are relevant to assessing HARI. These factors were generated from our review of the background literature and conversations with the SMEs. NASA stakeholders were informed that these factors would be weighted and used to conduct a trade study designed to help NASA in prioritizing which technologies and, consequently, which HARI research areas, should be further invested in to help with future long duration exploration missions. After our NASA stakeholders provided their input, we averaged and ranked their assessment of the factors. The ranked factors appear in Table 3.

% Factor	Weight
% Task applicability 	6
% Task enabling 	6
% Potential for reducing risk 	5
% Potential for introducing risk 	(-)4
% External Investment (outside of NASA) 	3
% Technology Readiness Level (TRL) 	2
% Research Interest (within NASA) 	1
% Table 3: The ranking of seven factors resulting from feedback from our NASA stakeholders

\subsubsection{Task applicability}
Which tasks does the technology have an impact on? This factor characterizes how much impact the technology may have on the various HARI tasks identified for future exploration missions [39]. We determined if each technology applies to each task in order to measure the technology's applicability to space HARI. These tasks, common to long duration orbital missions, deep space surface exploration missions, or both, are shown in Table 4.

% Applicable to Orbit Operations	Maneuver/reboost/rendezvous
% 	Docking/undocking
% 	Spacecraft support, system maintenance
% 	Complex assembly, capture and berth
% 	Science and assigned activity support, payload assistance
% 	Science and assigned activity support, crew assistance–physical
% 	Science and assigned activity support, crew assistance–cognitive
% Applicable to Surface Operations	Spacecraft support, system maintenance
% 	Spacecraft support, system preparation
% 	Site preparation assembly, excavation
% 	Complex assembly, heavy lift
% 	Drive/navigate
% 	Exploration, scouting
% 	Exploration, mapping
% 	Exploration, sampling/analyzing
% 	Science and assigned activity support, science/sample collection
% 	Science and assigned activity support, payload assistance
% 	Science and assigned activity support, crew assistance–physical
% 	Science and assigned activity support, crew assistance–cognitive
% Table 4: HAR tasks for spaceflight

\subsubsection{Task enabling}
Does the technology enable a new capability? This factor describes how much the technology enables one or more of the various HARI tasks identified for future exploration missions. HARI tasks are assumed to be critical and must be completed. We subjectively rated this by classifying the technology as: No effect relative to current technology (score of 0), Improves performance of current capability (score of 1), or Adds new capability (score of 2).

\subsubsection{Potential for reducing risk}
What is the benefit from risk reduction? This factor describes how risk might be reduced by the inclusion of the technology. Each type of risk was subjectively rated. Types of risks (secondary criteria) are listed below:
	Improved safety: increase astronauts’ safety.
	Reduced likelihood of system failure: increase overall robustness of system by predicting or preventing failures.
	Improved performance: astronauts can work more effectively and efficiently, including reducing physical and cognitive workload.

\subsubsection{Potential for introducing risk}
What is the cost from introduced risk? This factor describes how risk might be introduced by the inclusion of the technology. Each type of risk was subjectively rated. Types of risks are paired with the types of risk reduction. Note that, unlike all the other factors, a higher potential for introducing risk has a negative impact on the technologies overall score.

\subsubsection{External investment (outside NASA)}
What is the current research activity going on outside of NASA? This factor characterizes how much research and investment has recently and is currently going into the development of the technology by entities outside of NASA. This is just research on the technology, not HARI research investments. We measured this using the publication rate associated with each technology. The name of each technology was searched for on 6/24/2019 on Web of Science using the following search, where technology is substituted for each:
	ALL FIELDS: (technology)
	Timespan: 2013-2018. Indexes: SCI-EXPANDED, SSCI, A\&HCI, CPCI-S, CPCI-SSH, BKCI-S, BKCI-SSH, ESCI, CCR-EXPANDED, IC.
Similarly, the technologies were also searched for in Google Scholar on the same date and with the same time span. The sums from both searches were used to determine scores for this factor (see Trade Study Approach).

\subsubsection{Technology Readiness Level (TRL)}
What is the current TRL? This factor characterizes the maturity level of the technology. We estimated the technology's current TRL using information gathered from the literature and provided by our SMEs. TRL was split into three categories: Below TRL 3, TRL 3-5, and TRL 6 or greater.

\subsubsection{Research interest (within NASA)}
What is the current research interest within NASA? This factor describes if the technology has any potential for infusion into NASA missions as determined by the NASA Technology roadmaps/NASA Strategic Technology Investment Plan. We qualify this by checking if the technology is present on the NASA technology roadmap.

\subsection{Trade Study Approach}
A multi-dimensional trade analysis was performed to objectively score HARI research topics and specific technologies in a recommended order of priority for NASA investment. The approach used was similar to a Relationship Matrix Decomposition Scheme (RMDS) [40], see Figure 5. The factors for assessment described above pertain directly to HARI technologies, while research topics are assessed through direct relationships with those technologies, see Figure 5a. This parallels the RMDS approach of tracing assessment of system configurations and technology options based on objectives/goals through functional options, see Figure 5b. For the complete trade table used in this study, see Appendix A: Trade Analysis Tables.

\begin{figure}[tb!]
    \begin{center}
        \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{figures/TradeStudy/figure5a.png}
            \caption{Top-level trade study approach used in the HARI analysis}
            % \label{figure:}
        \end{subfigure}\hfill
        \begin{subfigure}{0.49\textwidth}
            \includegraphics[width=\linewidth]{figures/TradeStudy/figure5b.png}
            \caption{structure of the RMDS trade study approach}
            % \label{figure:}
        \end{subfigure}
        % \caption{}
    \end{center}
\end{figure}

Research topics and technologies were defined as related if a given technology supports the research topic such that its development would fundamentally drive investigation of that topic. Each technology was given a score resulting from the technology-factors dimension of the trade. The scores for each related technology for a given research topic were summed to achieve the total score for that topic.

The technology total scores represent a roll-up of individual weighted factor scores for each specific technology. At a factor level, normalized scores for each technology were determined in a series of one-dimensional factor-technology trade studies. These individual factor-level trades used to compile the factor-technology dimension are found in Appendix A: Trade Analysis Tables. The factor scores were multiplied by the factor weights as defined in the NASA Stakeholders section of this report and summed for each technology.

\subsubsection{Factor-Level Trades}
The factor-level trades for Risk Reduced, Risk Introduced, and TRL each assessed the specific technologies against three weighted options. Risk Reduced, for example assigned an individual score of 0 or 1 to each technology if it potentially reduced risk to crew, risk to mission/vehicle, or risk of loss of performance. Each potentially reduced risk was weighted (1 to 3) based on relative ranking as found by the NASA stakeholders. The total weighted scores for each technology (sum of weights x scores) were normalized by the highest possible score for a single technology to find the factor scores on a scale between 0 and 1 (see Equation 1, below).
% Normalized\ Score\ =\ \frac{\mathrm{\Sigma}(Weighted\ Scores\ for\ a\ Technology)}{\mathrm{\Sigma}(weights)\ast m a x(individual\ score)}\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ (1)
For Risk Introduced, normalized scores were multiplied by -1, as introduced risk were tallied as a negative contribution to overall technology assessment. The TRL trade was performed identically to Reduced Risk, with the exception that technologies could only be assigned to a single average TRL range. Assessment for Research Interest (within NASA) was simplified compared to other factor-level trades as scoring had a single binary level (trade table included in Appendix A: Trade Analysis Tables for completeness).

In the Task Applicability and Task Enabling factor-level trades, scores were assigned between technology and task, with equal weighting across tasks (all assigned a weight of 1). Technologies were assessed for Task Applicability with a score of 0 or 1, while for Task Enabling technologies were assigned a score for each task of 0, 1, or 2 as described in the NASA Stakeholders section.

In assessment of External Investment in NASA, as described previously, two search engines were used to find estimates on the number of recent publications pertaining to each technology. Searches with each service are known to poll databases of drastically different size. The relative database size used by both search engines was accounted for by applying a weight determined by the largest publication total found for each service. In this way, the relative publication totals for each service could be normalized independently prior to summing the results of the two searches.

\section{Results}

\subsection{Research Topics}
The final scores for research topics have been ranked, such that a high score represents a recommended higher priority for research investment by NASA (see ). The top-ranking research topics are:
	Improving training for HAR systems and tasks
	Establishing appropriate trust in automation/robotics systems
	Understanding human intent

  % Research Topic	Score	Rank
% Improving training for HAR systems and tasks	84.66	1
% Establishing appropriate trust in automation/robotics systems	79.27	2
% Understanding human intent	77.13	3
% Enabling command/control of complex robotic systems	72.80	4
% HAR team performance optimization and function allocation	68.76	5
% Autonomous/robotic system communication to humans	58.82	6
% Ensuring human safety (physical)	50.66	7
% Improving situation awareness in HAR systems	50.07	8
% Continuous human performance monitoring	44.68	9
% Table 5: The resulting prioritization of research topics from linking research topics to the upcoming technologies
Note that all these topics were identified as areas applicable to HARI concerns, regardless of the score. A high score here is highly dependent on the impact of the surveyed technologies on the research topic and suggests which research topics should be able to make relatively quick progress given the technology that is being developed now and in the next 5-10 years. A low score reflects research topics that either have relatively few technology solutions on the horizon, had relatively low factor scores for the technologies that are related to the topic, or both.

These top-ranking research topics were driven by their associated highly scoring technologies. Improving training for HAR systems and tasks touches on a variety of upcoming technologies ranging from machine learning to robotic/human information interfaces. These technologies ranked highly in their task applicability and potential for reducing risk and had relatively little potential for introducing new risks when compared to other technologies. By leveraging these upcoming technologies, researchers have ample opportunities to investigate novel techniques for improving training for these systems. These upcoming techniques will prove invaluable as HAR systems and tasks continue to increase in complexity, especially if, for example, they can provide crew with just-in-time training for critical tasks when they are far from the support provided by mission control. The topic of training came up many times in our conversations with subject matter experts, who often noted case examples of major failures in their explanations for why this training was needed. Similarly, many subject matter experts also mentioned the need for establishing appropriate trust in automation/robotics systems during our interviews, a topic which came up repeatedly in our review of the literature. Over-trust and under-trust in these complex systems were both noted as being dangerous and can result from inadequate training. Research in trust has often focused on its role in flexible, adaptive, and adaptable automation, where operators can be unclear which mode the system is in. By taking advantage of upcoming technologies in intuitive physical control and robotic/human information interfaces, researchers can help to bring humans into the loop on what is happening within these complex systems.

In contrast to the top-ranking research topics, continuous human performance monitoring and improving situation awareness in HAR systems were among the lowest ranked topics. While both are important when considering future long duration exploration missions, neither were directly associated with many upcoming technologies. Despite being associated with the top-ranking technology, machine learning, continuous human performance monitoring ranked lowest. This is primarily because it was also associated with the two lowest ranking technologies, non-invasive behavioral and physiological sensing and implantable biometrics. Despite these technologies’ clear relation to performance monitoring, they were among the lowest ranking when considering the task applicability and task enabling factors, which were considered the most important by our NASA stakeholders. Improving situation awareness in HAR systems lower score came as a surprise as situation awareness presents a challenge across all HAR applications. Although it also benefited from being linked to a top-ranking technology—robotic/human information interfaces—but the topic otherwise suffered from few direct technology solutions.

\subsection{Technologies}
The resulting ranks of the technologies from the weighted factors are shown in . The top-ranking technologies identified from the trade study are:
	Machine Learning
	Autonomous obstacle detection/imaging
	Robotic/human information interfaces
	Artificial Intelligence

% Technology	Score	Rank
% Machine Learning	19.33	1
% Autonomous obstacle detection/imaging	16.37	2
% Robotic/human information interfaces	15.86	3
% Artificial Intelligence	15.25	4
% Intuitive physical control interfaces	13.98	5
% Autonomous path planning	12.36	6
% Augmented Reality and Virtual Reality	12.29	7
% Robotic agents	12.25	8
% Flexible, Adaptive, or Adaptable Automation	12.24	9
% Assistive Robotics	9.69	10
% Speech recognition	8.78	11
% Non-invasive behavioral and physiological sensing	8.12	12
% Implantable Biometrics	4.98	13
% Table 6: The resulting prioritization of technologies using the trade study
These top-ranking technologies have seen enormous advancements in research interest and development over the past few years, and all offer a large benefit to the tasks required by NASA on future LDEMs. In contrast to the top-ranking technologies, low ranking technologies show a trend of reflecting a combination of low research interest, task relevance, or TRL.

The top-ranking technologies all benefited from high marks across all our factors. Machine learning, our top-ranking technology, particularly stands out due to scoring highest in the External Investment (outside of NASA) factor, where it significantly outperformed the other technologies. As we noted in the literature review, machine learning came has been repeatedly forecast as being essential to the future of human-robotic interaction [18]. It also came up extensively in our conversations with our subject matter experts, though several of these also stressed caution in assuming machine learning could solve any problem without issue. Artificial Intelligence was also mentioned by most of the SMEs but ranked lower due to its dramatically higher potential for introducing risk.

Autonomous obstacle detection/imaging was our second highest scoring factor but had little impact on our research topic recommendations. Despite being a well-established technology, the only topic is was ultimately related to was ensuring human safety (physical). Like our other high scoring technologies, however, it scored well due to its high task applicability, task enabling potential for reducing risk factors. This suggests that, while the technology should continue to be developed and refined, there is minimal applicability toward ongoing research that addresses outstanding HARI risks and challenges. Improvements resulting from refinement in the commercial sector, especially regarding autonomous cars, should enable faster and safer algorithms in the future.

Several technologies were highly clustered in the middle of our rankings: autonomous path planning, augmented reality/virtual reality, robotic agents, and flexible/adaptive/adaptable automation also scored within a few tenths of a point from each other. These technologies all had relatively high potential for introducing risk but were otherwise highly applicable to the tasks related to space HARI. As noted previously, the two lowest ranking technologies, non-invasive behavioral and physiological sensing and implantable biometrics were among the lowest ranking when considering the task applicability and task enabling factors, which were considered the most important by our NASA stakeholders. These technologies were also those which did not score in the Research Interest (within NASA) factor, as they were not present in the NASA Technology roadmaps or NASA Strategic Technology Investment Plan. The third lowest ranking technology, speech recognition, despite being a widespread, high TRL technology, scored poorly because it was the lowest scoring in both the task applicability and task enabling factors.

% \section{Contribution (Relation to NASA HARI Gaps)}
% NASA has identified four gaps in HARI knowledge, as part of the larger HFBP characterization of human factors risks and associated knowledge gaps [41]. These gaps need to be closed in order to mitigate HARI related risk as it pertains to spaceflight.
% The NASA HARI Gaps are:
% 	HARI-01: We need to evaluate, develop, and validate methods and guidelines for identifying human-automation/robot task information needs, function allocation, and team composition for future long duration, long distance space missions.
% 	HARI-02: We need to develop design guidelines for effective human-automation-robotic systems in operational environments that may include distributed, non-collocated adaptive mixed-agent teams with variable transmission latencies.
% 	HARI-03: We do not know how to quantify overall human-automation-robotic system performance to inform and evaluate system designs to ensure safe and efficient space mission operations.
% 	HARI-04: We need to identify and scope the critical human-automation/robotic mission activities and tasks that are required for future long duration, long distance space missions.

% This study extends prior investigation of HARI tasks, specifically to address gap HARI-04 directly. This investigation and trade study identify prioritized lists of specific technologies whose advancement support the activities and tasks required for future space exploration missions, as well as research topics where investment will support both HARI task capabilities and closing of the other three HARI knowledge gaps. All the research topics identified in this report can assist with closing HARI-02, and most address HARI-03 as well. Table 7 provides a complete mapping of the relationships between with research topics and HARI gaps. Although few of the research topics address HARI-01, the outstanding concerns identified by NASA for closer of HARI-01 pertain directly to the topics of safety and function allocation, which are reflected here.

% Research Topic	Gap HARI-01	Gap HARI-02	Gap HARI-03
% Understanding human intent	✓	✓	✓
% Autonomous/robotic system communication to humans		✓	✓
% Ensuring human safety (physical)	✓	✓	✓
% Continuous human performance monitoring		✓	✓
% HAR team performance optimization and function allocation	✓	✓	✓
% Enabling command/control of complex robotic systems		✓
% Improving situation awareness in HAR systems		✓	✓
% Improving training for HAR systems and tasks		✓
% Establishing appropriate trust in automation/robotics systems		✓	✓
% Table 7: Mapping of HARI related Research Topics to HARI Gaps identified by NASA

\section{Recommendations}
Based on the trade analysis performed, we recommend that NASA’s HFBP Element prioritizes research investment in the topics of improving training for HAR systems and tasks, establishing appropriate trust in autonomous/robotic systems, and understanding human intent. It is important to note that all the identified HARI research topics have application toward mitigating HARI risk in spaceflight tasks for future missions. These topics, however, represent the highest-priority areas for investment.

Investigation and identification of methods to improve training for HAR systems has the potential for far-reaching impact on reducing risk in mission operations, with limited chance of introducing new risk. Training is also a ubiquitous concern across all HAR systems and tasks. Similarly, establishing trust between the human and robotic/autonomous system showed trends of tracing to high risk reduction potential, though risk introduction potential was more varied. Trust between the human and the autonomous system (or robotic agent) came up again and again in discussions with experts across different HARI related disciplines as critical to the success of HAR operations. Without appropriate trust, elements fundamental to other research topics, such as teamwork or performance, break down.

While understanding human intent ranked highly as a research topic largely because of the number of technologies to which it was related, we believe this topic deserves its place in the prioritized rankings because, like training and establishment of trust, it stands out in overall potential to address HAR concerns for spaceflight. The ability to interpret human communication, input, need, and general intent is critical to the successful operation of any HAR system which interacts directly with a human user. Consequently, it is strongly tied to several of the other research topics defined (e.g. continuous human performance monitoring, enabling command/control of complex robotic systems) and investment in this area could bolster study in those lower-priority topics as well.

One of the primary outcomes from this research was to determine directions for HARI research that will close HARI risk and support capabilities for HAR tasks in space exploration. Investigation of these research topics will provide a fundamental foundation for addressing challenges that face implementation of HARI technology solutions. Improvement of training, trust, and human intent interpretation in HAR systems enables capability for a wide range of HAR space exploration tasks, both for long duration orbital missions and future planetary surface exploration.

\section{References}

TO DO

% [1]	H. Admoni and B. Scassellati, “Social Eye Gaze in Human-robot Interaction: A Review,” J. Hum.-Robot Interact., vol. 6, no. 1, pp. 25–63, May 2017.
% [2]	M. Ahmad, O. Mubin, and J. Orlando, “A Systematic Review of Adaptivity in Human-Robot Interaction,” Multimodal Technologies and Interaction, vol. 1, no. 3, p. 14, Sep. 2017.
% [3]	J. Y. Chen and M. J. Barnes, “Human–agent teaming for multirobot control: A review of human factors issues,” IEEE Transactions on Human-Machine Systems, vol. 44, no. 1, pp. 13–29, 2014.
% [4]	M. R. Endsley, “From Here to Autonomy: Lessons Learned From Human–Automation Research,” Hum Factors, vol. 59, no. 1, pp. 5–27, Feb. 2017.
% [5]	J. Guiochet, M. Machin, and H. Waeselynck, “Safety-critical advanced robots: A survey,” Robotics and Autonomous Systems, vol. 94, pp. 43–52, Aug. 2017.
% [6]	B. Kehoe, S. Patil, P. Abbeel, and K. Goldberg, “A Survey of Research on Cloud Robotics and Automation,” IEEE Transactions on Automation Science and Engineering, vol. 12, no. 2, pp. 398–409, Apr. 2015.
% [7]	A. Kolling, P. Walker, N. Chakraborty, K. Sycara, and M. Lewis, “Human Interaction With Robot Swarms: A Survey,” IEEE Transactions on Human-Machine Systems, vol. 46, no. 1, pp. 9–26, Feb. 2016.
% [8]	H. Liu and L. Wang, “Gesture recognition for human-robot collaboration: A review,” International Journal of Industrial Ergonomics, vol. 68, pp. 355–367, Nov. 2018.
% [9]	D. P. Losey, C. G. McDonald, E. Battaglia, and M. K. O’Malley, “A Review of Intent Detection, Arbitration, and Communication Aspects of Shared Control for Physical Human–Robot Interaction,” Appl. Mech. Rev, vol. 70, no. 1, pp. 010804-010804–19, Feb. 2018.
% [10]	Z. Lu, R. Happee, C. D. Cabrall, M. Kyriakidis, and J. C. de Winter, “Human factors of transitions in automated driving: A general framework and literature survey,” Transportation research part F: traffic psychology and behaviour, vol. 43, pp. 183–198, 2016.
% [11]	S. Ososky, D. Schuster, E. Phillips, and F. G. Jentsch, “Building Appropriate Trust in Human-Robot Teams,” in 2013 AAAI Spring Symposium Series, 2013.
% [12]	R. Parasuraman and C. D. Wickens, “Humans: Still vital after all these years of automation,” Human factors, vol. 50, no. 3, pp. 511–520, 2008.
% [13]	E. Phillips, K. E. Schaefer, D. R. Billings, F. Jentsch, and P. A. Hancock, “Human-animal Teams As an Analog for Future Human-robot Teams: Influencing Design and Fostering Trust,” J. Hum.-Robot Interact., vol. 5, no. 1, pp. 100–125, Mar. 2016.
% [14]	S. S. Rautaray and A. Agrawal, “Vision based hand gesture recognition for human computer interaction: a survey,” Artif Intell Rev, vol. 43, no. 1, pp. 1–54, Jan. 2015.
% [15]	K. E. Schaefer, J. Y. C. Chen, J. L. Szalma, and P. A. Hancock, “A Meta-Analysis of Factors Influencing the Development of Trust in Automation: Implications for Understanding Autonomy in Future Systems,” Hum Factors, vol. 58, no. 3, pp. 377–400, May 2016.
% [16]	T. B. Sheridan, “Human–Robot Interaction: Status and Challenges,” Hum Factors, vol. 58, no. 4, pp. 525–532, Jun. 2016.
% [17]	M. Vagia, A. A. Transeth, and S. A. Fjerdingen, “A literature review on the levels of automation during the years. What are the different taxonomies that have been proposed?,” Applied ergonomics, vol. 53, pp. 190–202, 2016.
% [18]	T.-M. Wang, Y. Tao, and H. Liu, “Current Researches and Future Development Trend of Intelligent Robot: A Review,” International Journal of Automation and Computing, vol. 15, no. 5, pp. 525–546, 2018.
% [19]	M. Zamora, E. Caldwell, J. Garcia-Rodriguez, J. Azorin-Lopez, and M. Cazorla, “Machine Learning Improves Human-Robot Interaction in Productive Environments: A Review,” in Advances in Computational Intelligence, 2017, pp. 283–293.
% [20]	Z. He, “Gesture Recognition Based on Tri-Axis Accelerometer Using 1D Gabor Filters,” in 2018 9th International Symposium on Parallel Architectures, Algorithms and Programming (PAAP), 2018, pp. 146–151.
% [21]	J. M. Beer, A. D. Fisk, and W. A. Rogers, “Toward a Framework for Levels of Robot Autonomy in Human-robot Interaction,” J. Hum.-Robot Interact., vol. 3, no. 2, pp. 74–99, Jul. 2014.
% [22]	D. B. Kaber, C. M. Perry, N. Segall, C. K. McClernon, and L. J. Prinzel, “Situation awareness implications of adaptive automation for information processing in an air traffic control-related task,” International Journal of Industrial Ergonomics, vol. 36, no. 5, pp. 447–462, May 2006.
% [23]	D. A. Norman and S. W. Draper, User Centered System Design; New Perspectives on Human-Computer Interaction. Hillsdale, NJ, USA: L. Erlbaum Associates Inc., 1986.
% [24]	P. Simoens, M. Dragone, and A. Saffiotti, “The Internet of Robotic Things: A review of concept, added value and applications,” International Journal of Advanced Robotic Systems, vol. 15, no. 1, p. 1729881418759424, Jan. 2018.
% [25]	J. D. Lee and K. A. See, “Trust in automation: Designing for appropriate reliance,” Human factors, vol. 46, no. 1, pp. 50–80, 2004.
% [26]	J.-Y. Jian, A. M. Bisantz, and C. G. Drury, “Foundations for an empirically determined scale of trust in automated systems,” International Journal of Cognitive Ergonomics, vol. 4, no. 1, pp. 53–71, 2000.
% [27]	B. M. Muir and N. Moray, “Trust in automation. Part II. Experimental studies of trust and human intervention in a process control simulation,” Ergonomics, vol. 39, no. 3, pp. 429–460, 1996.
% [28]	B. D. Seppelt and J. D. Lee, “Keeping the driver in the loop: Dynamic feedback to support appropriate use of imperfect vehicle control automation,” International Journal of Human-Computer Studies, vol. 125, pp. 66–80, May 2019.
% [29]	E. J. de Visser et al., “Almost human: Anthropomorphism increases trust resilience in cognitive agents,” Journal of Experimental Psychology: Applied, vol. 22, no. 3, pp. 331–349, 2016.
% [30]	K. E. Culley and P. Madhavan, “A note of caution regarding anthropomorphism in HCI agents,” Computers in Human Behavior, vol. 29, no. 3, pp. 577–579, May 2013.
% [31]	R. Pak, A. C. McLaughlin, and B. Bass, “A multi-level analysis of the effects of age and gender stereotypes on trust in anthropomorphic technology by younger and older adults,” Ergonomics, vol. 57, no. 9, pp. 1277–1289, Sep. 2014.
% [32]	F. M. F. Verberne, J. Ham, A. Ponnada, and C. J. H. Midden, “Trusting Digital Chameleons: The Effect of Mimicry by a Virtual Social Agent on User Trust,” in Persuasive Technology, 2013, pp. 234–245.
% [33]	P. M. Fitts, “Human engineering for an effective air-navigation and traffic-control system,” Ohio State University Foundation, Columbus, OH, 1951.
% [34]	P. Tsarouchi, S. Makris, and G. Chryssolouris, “Human–robot interaction review and challenges on task planning and programming,” International Journal of Computer Integrated Manufacturing, vol. 29, no. 8, pp. 916–931, Aug. 2016.
% [35]	R. Singh, T. Miller, J. Newn, L. Sonenberg, E. Velloso, and F. Vetere, “Combining Planning with Gaze for Online Human Intention Recognition,” in Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems, Richland, SC, 2018, pp. 488–496.
% [36]	K. Ruhland et al., “A Review of Eye Gaze in Virtual Agents, Social Robotics and HCI: Behaviour Generation, User Interaction and Perception,” Computer Graphics Forum, vol. 34, no. 6, pp. 299–326, 2015.
% [37]	H. A. Yanco, A. Norton, W. Ober, D. Shane, A. Skinner, and J. Vice, “Analysis of Human-robot Interaction at the DARPA Robotics Challenge Trials,” Journal of Field Robotics, vol. 32, no. 3, pp. 420–444, 2015.
% [38]	M. R. Endsley, “Toward a Theory of Situation Awareness in Dynamic Systems,” Hum Factors, vol. 37, no. 1, pp. 32–64, Mar. 1995.
% [39]	J. J. Marquez, B. D. Adelstein, M. L. Chang, S. R. Ellis, K. A. Hambuchen, and R. L. Howard, “Future Exploration Missions’ Tasks Associated with the Risk of Inadequate Design of Human and Automation/Robotic Integration,” 2017.
% [40]	Boppe, Charlie, “Program/Project Decision-Aiding Methodology Training,” Charles Stark Draper Laboratory, 18-May-2010.
% [41]	“HRR - Risk - Risk of Inadequate Design of Human and Automation/Robotic Integration.” [Online]. Available: https://humanresearchroadmap.nasa.gov/Risks/risk.aspx?i=163. [Accessed: 05-Aug-2019].


% \appendix
% \chapter{Appendix A: Trade Analysis Tables}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea1.png}
%         \caption{Top-level trade table with final research topic scores (top right), final technology scores based on factors (bottom) and weighted factor-level scores for each technology}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea2.png}
%         \caption{Technology to Task Applicability factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea3.png}
%         \caption{Technology to Task Enabling factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea4.png}
%         \caption{Technology to Risk Reduced factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea5.png}
%         \caption{Technology to Risk Introduced factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea6.png}
%         \caption{Technology to Research Interest (outside NASA) factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea7.png}
%         \caption{Technology to TRL factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figurea8.png}
%         \caption{Technology to Research Interest (within NASA) factor-level trade table}
%         % \label{figure:}
%     \end{center}
% \end{figure}

% Appendix B: Subject Matter Expert Summary of Backgrounds
% The SMEs interviewed to gather background information on the HARI trade space all have extensive experience in either HAR integration research, human factors, or both, in their respective fields. Additionally, three SMEs have experience in related fields: one person in data analytics, and two others in psychology/neuroscience. The SMEs have a wide range of experience addressing different research applications, captured in Table B1.

% SME	Background	Expertise
% 		Space	Aviation	Military	Medical	Automotive	Locomotive	Robotics (general)
% 1	Industry		x	x
% 2	Industry		x	x
% 3	Academia	x	x			x	x	x
% 4	Industry,
% Former NASA	x	x		x
% 5	Military			x	x			x
% 6	Academia, Industry				x	x
% 7	Academia	x	x	x			x
% 8	Academia,
% Industry		x					x
% 9	Academia	x			x			x
% 10	Industry,
% Former NASA	x			x	x
% Table B1: Background and application area expertise of interviewed subject matter experts
% Appendix C: Annotated Bibliography
% Parasuraman, Raja, and Christopher D. Wickens. "Humans: Still vital after all these years of automation." Human factors 50.3 (2008): 511-520.
% 	In their 2008 review, Parasuraman and Wickens discuss major discoveries and developments in levels and stages of automation, reliance on and compliance with automation, and adaptive automation. "Parasuraman, Sheridan, and Wickens (2000) accordingly proposed an extension of the LOA concept to four information-processing stages: (a) information acquisition, (b) information analysis, (c) decision making, and (d) action, with each stage having its own LOA scale (for similar scales, see Endsley & Kaber, 1999; Endsley & Kiris, 1995)."
% Ososky, Scott, et al. "Building Appropriate Trust in Human-Robot Teams." AAAI Spring Symposium: Trust and Autonomous Systems. 2013.
% 	In their 2013 paper, Ososky et al. describe autonomous, intelligent robots as teammates, rather than tools, and describe the importance of appropriate, rather than maximal, trust in the human-robot team. They discuss how human operators must create a sufficiently developed mental model of a robot to appropriately use it for tasks which the robot can perform superiorly to the human. They note that inaccurate mental models can create "pitfalls for robotic system misuse or disuse", and that accurate mental models are required for the human to appropriately trust the robot. They argue that appropriate trust in the robotic system leads to how the robotic system is ultimately used.
% Beer, Jenay M., Arthur D. Fisk, and Wendy A. Rogers. "Toward a framework for levels of robot autonomy in human-robot interaction." Journal of Human-Robot Interaction 3.2 (2014): 74-99.
% 	In their 2014 paper, Beer, Fisk, and Rogers outline a framework for levels of robot autonomy (LORA) for human-robot interaction (HRI), with the goal of allowing researchers to identify the impacts of autonomy on the interaction between human and robot. They outline a set of guidelines which can serve as "(1) a set of guidelines suggesting task and environmental influences on robot autonomy, (2) guidelines for determining or measuring autonomy, (3) a taxonomy for categorizing autonomy, and finally, (4) a set of HRI variables that may be influenced by robot autonomy."
% Chen, Jessie YC, and Michael J. Barnes. "Human–agent teaming for multirobot control: A review of human factors issues." IEEE Transactions on Human-Machine Systems 44.1 (2014): 13-29.
% 	In their 2014 paper, Chen and Barnes identified important human factors issued related to human-agent teams in multirobot control. They conclude that agents acting as interfaces between human operators and intelligent systems are an efficient way for operators to supervise multiple systems, while natural language processing is not required, the agents must have the ability to recognize operator intent, and that mixed initiative architectures can take advantage of both the human’s expertise and the agent’s precision and ability to act quickly. Mixed initiative systems, a subset of flexible automation, which allows for a dynamic level of automation based on the operator’s state and events in the environment. Chen and Barnes further note the importance of transparency in effectively calibrating operator trust in an autonomous system.
% Kehoe, Ben, et al. "A survey of research on cloud robotics and automation." IEEE Trans. Automation Science and Engineering 12.2 (2015): 398-409.
% 	Kehoe et al.’s 2015 paper considers robots and automation systems that rely on externally networked support, and focuses on the benefits of the cloud, including: big data, cloud computing, collective robot learning, and human computation. They note the state of the art in each of these areas while considering the current challenges and future directions research must should be taken. New issues associated with the rise in cloud technology include the need for techniques to consider time varying latency and quality of service, privacy concerns, and big data cleaning and filtering techniques. The note three levels at which a cloud computing framework are currently established: Infrastructure as a Service (IaaS), where bare operating systems are available; Platform as a Service (PaaS), where more structure is provided, including access to application frameworks, databases, and programming languages; and Software as a Service (SaaS), where software is made available online rather than as a local service. They conclude by proposing a fourth cloud framework, Robotics and Automation as a Service (RAaaS), which merges PaaS and SaaS frameworks to provide a cloud service which processes inputs for robotics, suggests output actions, and monitors results to update future recommendations.
% Rautaray, Siddharth S., and Anupam Agrawal. "Vision based hand gesture recognition for human computer interaction: a survey." Artificial Intelligence Review 43.1 (2015): 1-54.
% 	Rautaray and Agrawal's 2015 survey provides a summary of progress in the field of vision-based hand gesture recognition and reviews the three main phases of hand gesture recognition: detection, tracking, and recognition. They analyze existing literature and note the required advances to further improve hand gesture recognition systems. They note the primary application domains of hand gesture recognition are desktop applications, followed by gaming and sign language. In terms of the challenges of operating in real-time and robustness, the authors find that comparisons are difficult as there is no commonly accepted baseline technique to compare to. Psychological aspects of gestures have been found to play an important role in hand gesture recognition systems. The authors find that, despite plenty of research into the field, 3D based gesture representations are still less preferred to appearance-based hand gesture representations.
% Ruhland, Kerstin, et al. "A review of eye gaze in virtual agents, social robotics and hci: Behaviour generation, user interaction and perception." Computer Graphics Forum. Vol. 34. No. 6. 2015.
% 	Ruhland et al.'s 2015 review covers the state of the art in generating artificial entities which include attempts to replicate the human eye, the role of social robotics, and the human-computer interaction issues involved. They found that research into eye-gaze models would greatly benefit from a fundamental foundation, and that individual differences in eye gaze are often ignored as research has traditionally attempted to model and recreate general behavior. Human-robot interaction in the field of eye gaze has largely focused on shared attention and gaze cueing, factors that have affected task performance and user speech. The authors note several challenges mapping virtual to physical robots, especially that robot expression has fewer degrees of freedom. They also, however, suggest that physical systems may be able to better direct human gaze to targets of interest in a real environment as they can avoid the Mona Lisa gaze effect associated with virtual agents.
% Yanco, Holly A., et al. "Analysis of human‐robot interaction at the darpa robotics challenge trials." Journal of Field Robotics 32.3 (2015): 420-444.
% 	Yanco et al.'s 2015 paper reviewed team performance at the DARPA Robotics Challenge (DRC) trials, analyzing the results, team structure, and human-robotic interfaces. The DRC trials were designed to test humanoid robots' ability to respond to disaster scenarios where communications bandwidth was limited or degraded. Yanco et al.'s team analyzed 8 of the 15 teams which volunteered to participate in their study, observing their team interaction and robot's performance during the challenge. They identified four areas required for teams to be successful in the challenge: robot mobility, robot manipulation, situation awareness of the robot and its surroundings, and an effective way to command the robot. They further found that the most effective team was successful largely due to their: increased sensor fusion, which reduced the operator's cognitive load and reduced the need to repeat tasks; decreased number of operators, which both increased situational awareness and decreased the amount of required operator input.
% Kolling, Andreas, et al. "Human interaction with robot swarms: A survey." IEEE Transactions on Human-Machine Systems 46.1 (2016): 9-26.
% 	Kolling et al.’s 2016 review is the first survey of human-swarm interaction, and presents the basics of swarm robotics, the cognitive needs of a swarm operator, and the challenges involved with providing a human-swarm interface. They break the cognitive complexity of the human-robot system into three difficulties, using an analogy of computational complexity: robots performing independent activities, with complexity O(n), which allows more robots to be controlled simply by adding more operators in a linear manner; robots interacting with other robots fully autonomously, with complexity O(1), which allows for a fixed number of robots to control any number of robots; and the case where robot-robot interaction must be controlled by an operator, with complexity O(>n), as the dependencies between robots results in more demand faster than the number of robots grows. Under the assumption that O(1) complexity (only one operator) is desired, they review various control methods of conveying operator intent to the swarm.
% Phillips, Elizabeth, et al. "Human-animal teams as an analog for future human-robot teams: influencing design and fostering trust." Journal of Human-Robot Interaction 5.1 (2016): 100-125.
% 	In their 2016 paper, Phillips et al. discuss the advantages of human-animal teams as an analog for the ongoing development of human-robot teams. They discuss the ways that trust is established and changes in human-animal teaming, how these effects are beginning to be seen in human-robot teams, and how this trust determines how humans interact with their robotic teammates. They argue that including nonverbal communication in robots can help humans to better understand their actions and intents, allowing humans to form appropriate expectations of them. They further suggest that it may be beneficial, in the short term, to make robots more co-dependent on their users until these autonomous systems are capable of more sophisticated capabilities.
% Schaefer, Kristin E., et al. "A meta-analysis of factors influencing the development of trust in automation: Implications for understanding autonomy in future systems." Human factors 58.3 (2016): 377-400.
% 	Schaefer et al.’s 2016 meta-analysis reviews thirty studies to identify the significance of many factors influencing trust in automation. They first include three main moderators on trust, human, automation, and environment, and then further divide these main moderators into several submoderating effects. The authors observed that human-related factors have an overall moderate effect on trust development, and that automation or robotic capabilities play an important role on the formation of trust. They conclude by noting a large difference between human-robot interaction and human-automation interaction, attributing this to the need for more studies on system feature-based characteristics. They further recommend research on "the effects of human states, mode of communication, anthropomorphism, and agent transparency on trust development."
% Sheridan, Thomas B. "Human–robot interaction: status and challenges." Human factors 58.4 (2016): 525-532.
% 	In his 2016 paper, Sheridan discusses the state of human-robotic interaction and challenges, breaking the field into four areas: human supervisory control of robots for industrial tasks, teleoperation in hazardous environments, automated highway and rail vehicles, and commercial aircraft, and human-robot social interaction. He suggests that major human factors research challenges include: "(a) task analysis that includes dynamics, economics, and other factors; (b) teaching the robot and avoidance of unintended consequences; (c) considering how both human and robot have mutual models of each other; (d) use of robots in education; (e) coping with user culture, fears, and other value considerations."
% Tsarouchi, Panagiota, Sotiris Makris, and George Chryssolouris. "Human–robot interaction review and challenges on task planning and programming." International Journal of Computer Integrated Manufacturing 29.8 (2016): 916-931.
% 	Tsarouchi et al.'s 2016 review focuses on human-robotics interaction in the topics of task planning/coordination, intuitive programming, and communication frameworks. They also note important technologies and sensors for human-robotic interaction, which include visual guidance and imitation learning, vocal commanding, haptics and force control, and physical HRI and safety. They note voice guidance as one of the most promising interaction modalities, suggesting that it is "the most natural and intuitive way of communication", and that physical HRI applications are lacking despite considerable research into the field.
% Lu, Zhenji, et al. "Human factors of transitions in automated driving: A general framework and literature survey." Transportation research part F: traffic psychology and behaviour 43 (2016): 183-198.
% 	In their 2016 paper, Lu et al. propose a classification tree which distinguishes six types of transitions in automated driving, provide use cases for these transitions, and apply their proposed framework to a review of the literature of experimental research of transitions in automated driving. Their decision tree has three levels, based on the questions of "Who initiates the transition?", followed by "Who is in control after the transition?", and finally, "Is the transition required?". By utilizing the resulting six types of transitions and comparing to the research available in the literature, the authors were able to identify transitions which were rarely studied. They also consider the emerging abilities of adaptive automation. They end by noting that "[u]ntil the driving task is wholly automated under all possible circumstances and humans are prohibited from driving manually, transitions between the driver and the automation will remain a key element of automated driving."
% Vagia, Marialena, Aksel A. Transeth, and Sigurd A. Fjerdingen. "A literature review on the levels of automation during the years. What are the different taxonomies that have been proposed?." Applied ergonomics 53 (2016): 190-202.
% 	In their 2016 paper, Vagia et al. review the level of automation taxonomies that have been proposed since the 1950s, present the differences between these taxonomies, provide an example taxonomy generated from their review, and review the recent trend of adaptive automation. As a result of their review, Vagia et al. identified 24 automation level characteristics and present how their reviewed authors grouped them. They further identify which of these levels are popular among their reviewed authors and discuss how some levels are more appropriate than others based on the context in which level of automation is meant to be used. Vagia et al. stress that "[w]hat is important to remember is that amongst the different levels presented by the authors there exist no ‘correct’ or ‘wrong’ levels, ‘better or worse’ ones, they are just different. It would be wrong to claim that some levels are better than others, or that one taxonomy is the best one. To be accurate, there is no available tool in measuring how "good" or "bad" a taxonomy is, which gives the opportunity to every potential user to use the one that fits his needs better." They end by briefly noting the benefits of adaptive automation.
% Admoni, Henny, and Brian Scassellati. "Social eye gaze in human-robot interaction: a review." Journal of Human-Robot Interaction 6.1 (2017): 25-63.
% 	Admoni and Scassellati's 2017 paper reviews the state of the art in social eye gaze for human-robot interaction. They break the research field into three categories: human-focused, research that characterizes human behavior during robotic interaction, design-focused, research that focuses on how the design and behavior of a robot affects its interactions with humans, and technology-focused, which focuses on the computational tools for generating robotic eye gaze, and does not generally focus on human interactions. The human-focused research to date has shown that humans can identify the target of a robot’s gaze, but that humans tend to have different patterns of behavior between robotic gaze and gaze from other humans. The design-focused research has shown that "contextually contingent gaze is more effective than gaze behaviors that are uncorrelated with the interaction" and increases human performance in a variety of tasks across many metrics.
% Ahmad, Muneeb, Omar Mubin, and Joanne Orlando. "A systematic review of adaptivity in human-robot interaction." Multimodal Technologies and Interaction 1.3 (2017): 14.
% 	Ahmad et al.'s 2017 review covered reported adaptive interactions across several domains in human-robot interaction, which included healthcare and therapy, education, public domains and work environments, and homes. After reviewing 37 papers which included user studies, they summarize their results by domain and provide future directions and challenges. They note the recognition of emotion as "one of the key technical challenges in state of the art HRI", and that including the user's emotion can lead to greater social engagement. Another technical challenge involves robot memory, and that research is needed to produce more sophisticated methods based on a robot's previous interactions with a user. One issue with robot memory is user ethical concerns on their personal data storage, which are varied. The authors conclude by calling for a need for standardized evaluation metrics, noting that, while most results are driven from video analysis, there is "no protocol to analyze these videos for a set of measurements for different domains." They also conclude that most studies, though reporting positive findings, are only based on short term exposure with social robots, and that longitudinal research is needed to provide greater context.
% Endsley, Mica R. "From here to autonomy: lessons learned from human–automation research." Human factors 59.1 (2017): 5-27.
% 	Endsley's 2017 paper discusses the emerging problem of loss of operator situational awareness and out-of-the-loop performance problems associated with increasing system autonomy, reliability, and robustness. Endsley presents a model for human-autonomy system oversight (HASO), incorporating situation awareness, trust, workload and automation interfaces among the key system design features influencing human cognitive processes involved in successful interaction with automated systems. Twenty guidelines for the design of human-autonomy systems are presented, based off twenty years of research and an extensive literature search. Endsley closes her review by noting a number of areas where further research is required to realize fully autonomous systems: autonomy software validation, as traditional software testing techniques are not sufficient for testing autonomy because exhaustive state testing is difficult or impossible; learning system consistency, as there is concern that individuals acting with many different autonomous systems will be unclear how the current system interprets and adapts to their behavior, which leads to; transparency of learning systems, where it is both difficult for human operators to understand how machine learning techniques incorporate new information and for software programmers to understand what the system will do in every situation. While systems have an ever-increasing level of autonomy and intervention is increasingly rare, there are still situations where human intervention is required. Maintaining situational awareness in these systems will pose a continued problem for the foreseeable future.
% Guiochet, Jérémie, Mathilde Machin, and Hélène Waeselynck. "Safety-critical advanced robots: A survey." Robotics and Autonomous Systems 94 (2017): 43-52.
% 	Guiochet et al.'s 2017 survey discusses the deployment of advanced robotic applications to "real life" outside the laboratory and manufacturing warehouse. The authors suggest that the major question about robots is "how can we trust them?" and continue to discuss dependability and safety as two active issues and fields of work. They discuss the requirements to product commercialization in Europe, and robotics specific standards that have recently been released for industrial (ISO 10218:2011) and personal robots (ISO 13482:2014), which the authors note as lacking. In order to discuss dependability, the definition of which the authors use "ability to deliver service that can justifiably be trusted", the authors discuss the challenges associated with fault prevention, fault removal, fault forecasting, and fault tolerance. The authors end by noting the current challenges for dependability in autonomous systems, including adaptive safety monitoring, modeling and simulation for safety analysis, perception of hazardous situations, and human-robot interaction models.
% Zamora, Mauricio, et al. "Machine learning improves human-robot interaction in productive environments: a review." International Work-Conference on Artificial Neural Networks. Springer, Cham, 2017.
% 	Zamora et al.'s 2017 review presents the necessary technologies for effectively linking humans, robots, and intelligent and traditional machines in the new generation of Industry 4.0. They identify machine learning, computer vision, and augmented reality as three fundamental upcoming technologies. They discuss human-robot interaction in manufacturing regarding robotic level of autonomy, noting that most robots are controlled largely by humans, and that few could be fully controlled by artificial intelligence. In reviewing which machine learning algorithms are currently being used, they found that neural networks accounted for an overwhelming majority, but that both supervised and unsupervised algorithms were about equally common. Their discussion proposes a future for manufacturing where robots use computer vision to detect human intentions, humans use augmented reality interfaces to view robot intentions, and artificial intelligence enables an optimal manufacturing workflow.
% Liu, Hongyi, and Lihui Wang. "Gesture recognition for human-robot collaboration: A review." International Journal of Industrial Ergonomics 68 (2018): 355-367.
% 	Liu and Wang’s 2018 review of covers the most essential technologies and algorithms for gesture recognition and human-robot collaboration. Their review breaks gesture recognition into four technical components for further discussion: sensor technologies, gesture identification, gesture tracking and gesture classification. Reviewing these technical components, they note the advantages and disadvantages to the different approaches within each. They end by noting that non-wearable sensors development and deep learning-based gesture recognition systems as the most promising upcoming technologies.
% Losey, Dylan P., et al. "A Review of Intent Detection, Arbitration, and Communication Aspects of Shared Control for Physical Human–Robot Interaction." Applied Mechanics Reviews 70.1 (2018): 010804.

% \begin{figure}[b!]
%     \begin{center}
%         \includegraphics[width=0.8\linewidth]{figures/TradeStudy/figureb1.png}
%         \caption{Losey et al.'s proposed framework for human-robot interaction with the environment.}
%         % \label{figure:}
%     \end{center}
% \end{figure}
% 	Losey et al.'s 2018 review discusses the state of the art in the field of physical human-robot interaction, where human abilities are enhanced or supported by robotic aids, and discuss the human factors involved with shared task execution between the human and robot. They present a unified view of shared human-robot control in physical task execution, using case studies of applications in healthcare to demonstrate their framework. Their framework focuses on three distinct phases of decision making: detection, the task of understanding the human's intent; arbitration, the task of distributing control between the human and robot; and feedback, the task of presenting the result of the human's intent, which is often done through haptic devices. One ongoing field of research in physical human-robot interaction is that of dynamic changes in role arbitration using machine learning and artificial intelligence techniques. The authors note role arbitration should re-evaluated when trust changes, and further note "robotic performance has the largest and most identifiable influence on trust in HRI." As such, the real-time monitoring of performance metrics is an area of active research.

% Wang, Tian-Miao, Yong Tao, and Hui Liu. "Current Researches and Future Development Trend of Intelligent Robot: A Review." International Journal of Automation and Computing (2018): 1-22.
% 	In their 2018 review, Wang et al. discuss current research and future development trends of "intelligent" robots. They note several key and leading technologies in the field of robotics. They include key technologies such as human-robot collaboration technology, autonomous navigation technology under non-structured environments, multi-agent robot systems (swarms), and emotion recognition and interaction mechanism of robot oriented to harmonious human-robot cooperation. They also highlight innovative leading technologies such as brain computer interfaces, brain-like robot control and decision making (artificial intelligence and supervised/unsupervised learning techniques), material cross-innovation and applications of robot oriented to software structure (3D printed materials, soft grippers, flexible robots), and network decision mechanism of robot based on cloud computing and big data (IoT, SLAM). Their review further breaks down these technology areas into more specific, individual technologies and notes the current state of the art in each.

